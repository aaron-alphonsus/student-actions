{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/single_affect_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recent-science",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignment_action_id</th>\n",
       "      <th>assignment_log_id</th>\n",
       "      <th>student_user_xid</th>\n",
       "      <th>action_time</th>\n",
       "      <th>action_name</th>\n",
       "      <th>action_name-2</th>\n",
       "      <th>extended_action_name</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>seconds_since_last_action</th>\n",
       "      <th>teacher_xid</th>\n",
       "      <th>category_name</th>\n",
       "      <th>teacher_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4860314</td>\n",
       "      <td>122949</td>\n",
       "      <td>41904</td>\n",
       "      <td>21:49.8</td>\n",
       "      <td>AssignmentStartedAction</td>\n",
       "      <td>AssignmentStartedAction</td>\n",
       "      <td>AssignmentStartedAction_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4860315</td>\n",
       "      <td>122949</td>\n",
       "      <td>41904</td>\n",
       "      <td>21:49.8</td>\n",
       "      <td>ProblemSetStartedAction</td>\n",
       "      <td>ProblemSetStartedAction</td>\n",
       "      <td>ProblemSetStartedAction_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4860316</td>\n",
       "      <td>122949</td>\n",
       "      <td>41904</td>\n",
       "      <td>21:50.0</td>\n",
       "      <td>ProblemSetStartedAction</td>\n",
       "      <td>ProblemSetStartedAction</td>\n",
       "      <td>ProblemSetStartedAction_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4860317</td>\n",
       "      <td>122949</td>\n",
       "      <td>41904</td>\n",
       "      <td>21:50.2</td>\n",
       "      <td>ProblemStartedAction</td>\n",
       "      <td>ProblemStartedAction</td>\n",
       "      <td>ProblemStartedAction_false</td>\n",
       "      <td>0 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4860597</td>\n",
       "      <td>122949</td>\n",
       "      <td>41904</td>\n",
       "      <td>22:46.7</td>\n",
       "      <td>StudentResponseAction</td>\n",
       "      <td>StudentResponseAction</td>\n",
       "      <td>StudentResponseAction_false</td>\n",
       "      <td>Figure 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.466</td>\n",
       "      <td>8926.0</td>\n",
       "      <td>Thoughtful self correcting</td>\n",
       "      <td>Great job sticking with it until you got the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151602</th>\n",
       "      <td>309446359</td>\n",
       "      <td>6818428</td>\n",
       "      <td>1164303</td>\n",
       "      <td>42:44.3</td>\n",
       "      <td>StudentSubmissionAction</td>\n",
       "      <td>StudentSubmissionAction</td>\n",
       "      <td>StudentSubmissionAction_true</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151603</th>\n",
       "      <td>309446379</td>\n",
       "      <td>6818428</td>\n",
       "      <td>1164303</td>\n",
       "      <td>42:44.3</td>\n",
       "      <td>ProblemFinishedAction</td>\n",
       "      <td>ProblemFinishedAction</td>\n",
       "      <td>ProblemFinishedAction_true</td>\n",
       "      <td>226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151604</th>\n",
       "      <td>309446380</td>\n",
       "      <td>6818428</td>\n",
       "      <td>1164303</td>\n",
       "      <td>42:44.4</td>\n",
       "      <td>ProblemSetFinishedAction</td>\n",
       "      <td>ProblemSetFinishedAction</td>\n",
       "      <td>ProblemSetFinishedAction_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151605</th>\n",
       "      <td>309446381</td>\n",
       "      <td>6818428</td>\n",
       "      <td>1164303</td>\n",
       "      <td>42:44.4</td>\n",
       "      <td>ProblemSetFinishedAction</td>\n",
       "      <td>ProblemSetFinishedAction</td>\n",
       "      <td>ProblemSetFinishedAction_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151606</th>\n",
       "      <td>309446540</td>\n",
       "      <td>6818428</td>\n",
       "      <td>1164303</td>\n",
       "      <td>42:44.5</td>\n",
       "      <td>AssignmentFinishedAction</td>\n",
       "      <td>AssignmentFinishedAction</td>\n",
       "      <td>AssignmentFinishedAction_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151607 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        assignment_action_id  assignment_log_id  student_user_xid action_time  \\\n",
       "0                    4860314             122949             41904     21:49.8   \n",
       "1                    4860315             122949             41904     21:49.8   \n",
       "2                    4860316             122949             41904     21:50.0   \n",
       "3                    4860317             122949             41904     21:50.2   \n",
       "4                    4860597             122949             41904     22:46.7   \n",
       "...                      ...                ...               ...         ...   \n",
       "151602             309446359            6818428           1164303     42:44.3   \n",
       "151603             309446379            6818428           1164303     42:44.3   \n",
       "151604             309446380            6818428           1164303     42:44.4   \n",
       "151605             309446381            6818428           1164303     42:44.4   \n",
       "151606             309446540            6818428           1164303     42:44.5   \n",
       "\n",
       "                     action_name             action_name-2  \\\n",
       "0        AssignmentStartedAction   AssignmentStartedAction   \n",
       "1        ProblemSetStartedAction   ProblemSetStartedAction   \n",
       "2        ProblemSetStartedAction   ProblemSetStartedAction   \n",
       "3           ProblemStartedAction      ProblemStartedAction   \n",
       "4          StudentResponseAction     StudentResponseAction   \n",
       "...                          ...                       ...   \n",
       "151602   StudentSubmissionAction   StudentSubmissionAction   \n",
       "151603     ProblemFinishedAction     ProblemFinishedAction   \n",
       "151604  ProblemSetFinishedAction  ProblemSetFinishedAction   \n",
       "151605  ProblemSetFinishedAction  ProblemSetFinishedAction   \n",
       "151606  AssignmentFinishedAction  AssignmentFinishedAction   \n",
       "\n",
       "                extended_action_name answer_text  answer_correctness  \\\n",
       "0           AssignmentStartedAction_         NaN                 NaN   \n",
       "1           ProblemSetStartedAction_         NaN                 NaN   \n",
       "2           ProblemSetStartedAction_         NaN                 NaN   \n",
       "3         ProblemStartedAction_false         0 2                 0.0   \n",
       "4        StudentResponseAction_false    Figure 2                 0.0   \n",
       "...                              ...         ...                 ...   \n",
       "151602  StudentSubmissionAction_true          58                 1.0   \n",
       "151603    ProblemFinishedAction_true         226                 1.0   \n",
       "151604     ProblemSetFinishedAction_         NaN                 NaN   \n",
       "151605     ProblemSetFinishedAction_         NaN                 NaN   \n",
       "151606     AssignmentFinishedAction_         NaN                 NaN   \n",
       "\n",
       "        seconds_since_last_action  teacher_xid               category_name  \\\n",
       "0                             NaN          NaN                         NaN   \n",
       "1                           0.010          NaN                         NaN   \n",
       "2                           0.170          NaN                         NaN   \n",
       "3                           0.186          NaN                         NaN   \n",
       "4                          56.466       8926.0  Thoughtful self correcting   \n",
       "...                           ...          ...                         ...   \n",
       "151602                     89.018          NaN                         NaN   \n",
       "151603                      0.006          NaN                         NaN   \n",
       "151604                      0.079          NaN                         NaN   \n",
       "151605                      0.040          NaN                         NaN   \n",
       "151606                      0.060          NaN                         NaN   \n",
       "\n",
       "                                         teacher_feedback  \n",
       "0                                                     NaN  \n",
       "1                                                     NaN  \n",
       "2                                                     NaN  \n",
       "3                                                     NaN  \n",
       "4       Great job sticking with it until you got the r...  \n",
       "...                                                   ...  \n",
       "151602                                                NaN  \n",
       "151603                                                NaN  \n",
       "151604                                                NaN  \n",
       "151605                                                NaN  \n",
       "151606                                                NaN  \n",
       "\n",
       "[151607 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-desperate",
   "metadata": {},
   "source": [
    "# Preprocess to set all answer texts to None when not StudentResponseAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broadband-track",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN             66596\n",
       "3                1837\n",
       "4                1683\n",
       "2                1548\n",
       "No               1495\n",
       "                ...  \n",
       "-1-1x               1\n",
       "18x^14              1\n",
       "2.5^2               1\n",
       "(1/3)x+(1/3)        1\n",
       "1015                1\n",
       "Name: answer_text, Length: 15347, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.answer_text.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advance-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.action_name != \"StudentResponseAction\", \"answer_text\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "furnished-replacement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                  126560\n",
       "No                      704\n",
       "3                       516\n",
       "Yes                     506\n",
       "4                       463\n",
       "                      ...  \n",
       "C , E , H                 1\n",
       "0.83                      1\n",
       "7,000                     1\n",
       "375                       1\n",
       "(-2,-2) and (4,2)         1\n",
       "Name: answer_text, Length: 2887, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.answer_text.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-wyoming",
   "metadata": {},
   "source": [
    "There are 59964 instances of answer_text that have now been made NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-terrorist",
   "metadata": {},
   "source": [
    "# Preprocess to create label: 1 if Thoughtful self correcting, 0 if other label, NaN if not graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "settled-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                                                                            143458\n",
       "Struggled and requested answer                                                                   1257\n",
       "Thoughtful self correcting                                                                       1177\n",
       "Thoughtful Correct Response                                                                      1039\n",
       "Guessing after first attempt and gave up                                                          742\n",
       "Gave up after first attempt                                                                       597\n",
       "Gave up after two attempts                                                                        527\n",
       "Guessing after first attempt                                                                      447\n",
       "Fast self correcting                                                                              442\n",
       "No attempt                                                                                        415\n",
       "Struggled and persevered                                                                          315\n",
       "Guessing followed by requesting answer                                                            278\n",
       "Guessing                                                                                          266\n",
       "Fast correct response                                                                             149\n",
       "Gave up after more than three attempts                                                            111\n",
       "Many Guesses                                                                                      110\n",
       "Persevered after many attempts                                                                     66\n",
       "Format of answer incorrect                                                                         61\n",
       "Gave up after one guess                                                                            57\n",
       "Requested answer after several guesses                                                             30\n",
       "Using hint effectively                                                                             22\n",
       "No attempt                                                                                         21\n",
       "Requested answer after one guess                                                                    6\n",
       "Requested answer after no attempt but took time.                                                    4\n",
       "Gave up                                                                                             4\n",
       "Gave up                                                                                             3\n",
       "Using hint effectivelyGreat job!  I am happy to see that the hint helped you figure it out!         2\n",
       "Taking time                                                                                         1\n",
       "Name: category_name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category_name.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minute-villa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    150430\n",
       "1      1177\n",
       "Name: category_name, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.category_name == 'Thoughtful self correcting').astype(int).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "following-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = (df.category_name == 'Thoughtful self correcting').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prepared-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.teacher_xid.isna().value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "happy-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df.teacher_xid.isna(), \"label\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excited-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.label.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-nation",
   "metadata": {},
   "source": [
    "# Process 'seconds_since_last_action'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opponent-double",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    148498\n",
       "True       3109\n",
       "Name: seconds_since_last_action, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.seconds_since_last_action.isna().value_counts() # Check if any are na to fill with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "automatic-pathology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='action_name', ylabel='seconds_since_last_action'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['action_name', 'seconds_since_last_action']].plot.scatter(x='action_name', y='seconds_since_last_action', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "single-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.action_name == \"AssignmentResumedAction\", \"seconds_since_last_action\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wrapped-friend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='action_name', ylabel='seconds_since_last_action'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['action_name', 'seconds_since_last_action']].plot.scatter(x='action_name', y='seconds_since_last_action', rot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-research",
   "metadata": {},
   "source": [
    "# Subset dataset to get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forbidden-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = df[['seconds_since_last_action', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intellectual-writer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seconds_since_last_action</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151602</th>\n",
       "      <td>89.018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151603</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151604</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151605</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151606</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151607 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        seconds_since_last_action  label\n",
       "0                             NaN      0\n",
       "1                           0.010      0\n",
       "2                           0.170      0\n",
       "3                           0.186      0\n",
       "4                          56.466      1\n",
       "...                           ...    ...\n",
       "151602                     89.018      0\n",
       "151603                      0.006      0\n",
       "151604                      0.079      0\n",
       "151605                      0.040      0\n",
       "151606                      0.060      0\n",
       "\n",
       "[151607 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "analyzed-lover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnswerRequestedAction_</th>\n",
       "      <th>AssignmentFinishedAction_</th>\n",
       "      <th>AssignmentResumedAction_</th>\n",
       "      <th>AssignmentStartedAction_</th>\n",
       "      <th>HintRequestedAction_false</th>\n",
       "      <th>HintRequestedAction_true</th>\n",
       "      <th>ProblemFinishedAction_</th>\n",
       "      <th>ProblemFinishedAction_false</th>\n",
       "      <th>ProblemFinishedAction_true</th>\n",
       "      <th>ProblemResumedAction_</th>\n",
       "      <th>...</th>\n",
       "      <th>ProblemStartedAction_</th>\n",
       "      <th>ProblemStartedAction_false</th>\n",
       "      <th>ProblemStartedAction_true</th>\n",
       "      <th>StudentResponseAction_false</th>\n",
       "      <th>StudentResponseAction_true</th>\n",
       "      <th>StudentSubmissionAction_false</th>\n",
       "      <th>StudentSubmissionAction_true</th>\n",
       "      <th>TutoringSetFinishedAction_</th>\n",
       "      <th>TutoringSetStartedAction_</th>\n",
       "      <th>UserSelectedContinueAction_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151602</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151605</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151606</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151607 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AnswerRequestedAction_  AssignmentFinishedAction_  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "...                        ...                        ...   \n",
       "151602                       0                          0   \n",
       "151603                       0                          0   \n",
       "151604                       0                          0   \n",
       "151605                       0                          0   \n",
       "151606                       0                          1   \n",
       "\n",
       "        AssignmentResumedAction_  AssignmentStartedAction_  \\\n",
       "0                              0                         1   \n",
       "1                              0                         0   \n",
       "2                              0                         0   \n",
       "3                              0                         0   \n",
       "4                              0                         0   \n",
       "...                          ...                       ...   \n",
       "151602                         0                         0   \n",
       "151603                         0                         0   \n",
       "151604                         0                         0   \n",
       "151605                         0                         0   \n",
       "151606                         0                         0   \n",
       "\n",
       "        HintRequestedAction_false  HintRequestedAction_true  \\\n",
       "0                               0                         0   \n",
       "1                               0                         0   \n",
       "2                               0                         0   \n",
       "3                               0                         0   \n",
       "4                               0                         0   \n",
       "...                           ...                       ...   \n",
       "151602                          0                         0   \n",
       "151603                          0                         0   \n",
       "151604                          0                         0   \n",
       "151605                          0                         0   \n",
       "151606                          0                         0   \n",
       "\n",
       "        ProblemFinishedAction_  ProblemFinishedAction_false  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "...                        ...                          ...   \n",
       "151602                       0                            0   \n",
       "151603                       0                            0   \n",
       "151604                       0                            0   \n",
       "151605                       0                            0   \n",
       "151606                       0                            0   \n",
       "\n",
       "        ProblemFinishedAction_true  ProblemResumedAction_  ...  \\\n",
       "0                                0                      0  ...   \n",
       "1                                0                      0  ...   \n",
       "2                                0                      0  ...   \n",
       "3                                0                      0  ...   \n",
       "4                                0                      0  ...   \n",
       "...                            ...                    ...  ...   \n",
       "151602                           0                      0  ...   \n",
       "151603                           1                      0  ...   \n",
       "151604                           0                      0  ...   \n",
       "151605                           0                      0  ...   \n",
       "151606                           0                      0  ...   \n",
       "\n",
       "        ProblemStartedAction_  ProblemStartedAction_false  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           1   \n",
       "4                           0                           0   \n",
       "...                       ...                         ...   \n",
       "151602                      0                           0   \n",
       "151603                      0                           0   \n",
       "151604                      0                           0   \n",
       "151605                      0                           0   \n",
       "151606                      0                           0   \n",
       "\n",
       "        ProblemStartedAction_true  StudentResponseAction_false  \\\n",
       "0                               0                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            1   \n",
       "...                           ...                          ...   \n",
       "151602                          0                            0   \n",
       "151603                          0                            0   \n",
       "151604                          0                            0   \n",
       "151605                          0                            0   \n",
       "151606                          0                            0   \n",
       "\n",
       "        StudentResponseAction_true  StudentSubmissionAction_false  \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "...                            ...                            ...   \n",
       "151602                           0                              0   \n",
       "151603                           0                              0   \n",
       "151604                           0                              0   \n",
       "151605                           0                              0   \n",
       "151606                           0                              0   \n",
       "\n",
       "        StudentSubmissionAction_true  TutoringSetFinishedAction_  \\\n",
       "0                                  0                           0   \n",
       "1                                  0                           0   \n",
       "2                                  0                           0   \n",
       "3                                  0                           0   \n",
       "4                                  0                           0   \n",
       "...                              ...                         ...   \n",
       "151602                             1                           0   \n",
       "151603                             0                           0   \n",
       "151604                             0                           0   \n",
       "151605                             0                           0   \n",
       "151606                             0                           0   \n",
       "\n",
       "        TutoringSetStartedAction_  UserSelectedContinueAction_  \n",
       "0                               0                            0  \n",
       "1                               0                            0  \n",
       "2                               0                            0  \n",
       "3                               0                            0  \n",
       "4                               0                            0  \n",
       "...                           ...                          ...  \n",
       "151602                          0                            0  \n",
       "151603                          0                            0  \n",
       "151604                          0                            0  \n",
       "151605                          0                            0  \n",
       "151606                          0                            0  \n",
       "\n",
       "[151607 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df.extended_action_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "romantic-buddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnswerRequestedAction_</th>\n",
       "      <th>AssignmentFinishedAction_</th>\n",
       "      <th>AssignmentResumedAction_</th>\n",
       "      <th>AssignmentStartedAction_</th>\n",
       "      <th>HintRequestedAction_false</th>\n",
       "      <th>HintRequestedAction_true</th>\n",
       "      <th>ProblemFinishedAction_</th>\n",
       "      <th>ProblemFinishedAction_false</th>\n",
       "      <th>ProblemFinishedAction_true</th>\n",
       "      <th>ProblemResumedAction_</th>\n",
       "      <th>...</th>\n",
       "      <th>ProblemStartedAction_true</th>\n",
       "      <th>StudentResponseAction_false</th>\n",
       "      <th>StudentResponseAction_true</th>\n",
       "      <th>StudentSubmissionAction_false</th>\n",
       "      <th>StudentSubmissionAction_true</th>\n",
       "      <th>TutoringSetFinishedAction_</th>\n",
       "      <th>TutoringSetStartedAction_</th>\n",
       "      <th>UserSelectedContinueAction_</th>\n",
       "      <th>seconds_since_last_action</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151602</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151605</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151606</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151607 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AnswerRequestedAction_  AssignmentFinishedAction_  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "...                        ...                        ...   \n",
       "151602                       0                          0   \n",
       "151603                       0                          0   \n",
       "151604                       0                          0   \n",
       "151605                       0                          0   \n",
       "151606                       0                          1   \n",
       "\n",
       "        AssignmentResumedAction_  AssignmentStartedAction_  \\\n",
       "0                              0                         1   \n",
       "1                              0                         0   \n",
       "2                              0                         0   \n",
       "3                              0                         0   \n",
       "4                              0                         0   \n",
       "...                          ...                       ...   \n",
       "151602                         0                         0   \n",
       "151603                         0                         0   \n",
       "151604                         0                         0   \n",
       "151605                         0                         0   \n",
       "151606                         0                         0   \n",
       "\n",
       "        HintRequestedAction_false  HintRequestedAction_true  \\\n",
       "0                               0                         0   \n",
       "1                               0                         0   \n",
       "2                               0                         0   \n",
       "3                               0                         0   \n",
       "4                               0                         0   \n",
       "...                           ...                       ...   \n",
       "151602                          0                         0   \n",
       "151603                          0                         0   \n",
       "151604                          0                         0   \n",
       "151605                          0                         0   \n",
       "151606                          0                         0   \n",
       "\n",
       "        ProblemFinishedAction_  ProblemFinishedAction_false  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "...                        ...                          ...   \n",
       "151602                       0                            0   \n",
       "151603                       0                            0   \n",
       "151604                       0                            0   \n",
       "151605                       0                            0   \n",
       "151606                       0                            0   \n",
       "\n",
       "        ProblemFinishedAction_true  ProblemResumedAction_  ...  \\\n",
       "0                                0                      0  ...   \n",
       "1                                0                      0  ...   \n",
       "2                                0                      0  ...   \n",
       "3                                0                      0  ...   \n",
       "4                                0                      0  ...   \n",
       "...                            ...                    ...  ...   \n",
       "151602                           0                      0  ...   \n",
       "151603                           1                      0  ...   \n",
       "151604                           0                      0  ...   \n",
       "151605                           0                      0  ...   \n",
       "151606                           0                      0  ...   \n",
       "\n",
       "        ProblemStartedAction_true  StudentResponseAction_false  \\\n",
       "0                               0                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            1   \n",
       "...                           ...                          ...   \n",
       "151602                          0                            0   \n",
       "151603                          0                            0   \n",
       "151604                          0                            0   \n",
       "151605                          0                            0   \n",
       "151606                          0                            0   \n",
       "\n",
       "        StudentResponseAction_true  StudentSubmissionAction_false  \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "...                            ...                            ...   \n",
       "151602                           0                              0   \n",
       "151603                           0                              0   \n",
       "151604                           0                              0   \n",
       "151605                           0                              0   \n",
       "151606                           0                              0   \n",
       "\n",
       "        StudentSubmissionAction_true  TutoringSetFinishedAction_  \\\n",
       "0                                  0                           0   \n",
       "1                                  0                           0   \n",
       "2                                  0                           0   \n",
       "3                                  0                           0   \n",
       "4                                  0                           0   \n",
       "...                              ...                         ...   \n",
       "151602                             1                           0   \n",
       "151603                             0                           0   \n",
       "151604                             0                           0   \n",
       "151605                             0                           0   \n",
       "151606                             0                           0   \n",
       "\n",
       "        TutoringSetStartedAction_  UserSelectedContinueAction_  \\\n",
       "0                               0                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "151602                          0                            0   \n",
       "151603                          0                            0   \n",
       "151604                          0                            0   \n",
       "151605                          0                            0   \n",
       "151606                          0                            0   \n",
       "\n",
       "        seconds_since_last_action  label  \n",
       "0                             NaN      0  \n",
       "1                           0.010      0  \n",
       "2                           0.170      0  \n",
       "3                           0.186      0  \n",
       "4                          56.466      1  \n",
       "...                           ...    ...  \n",
       "151602                     89.018      0  \n",
       "151603                      0.006      0  \n",
       "151604                      0.079      0  \n",
       "151605                      0.040      0  \n",
       "151606                      0.060      0  \n",
       "\n",
       "[151607 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.get_dummies(df['extended_action_name']), data_subset], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-purchase",
   "metadata": {},
   "source": [
    "input shape has 24 columns (exclude label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-confusion",
   "metadata": {},
   "source": [
    "# Stratify dataset by student id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "seven-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_students = df.student_user_xid.unique()\n",
    "np.random.shuffle(unique_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stable-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_tenfold = np.array_split(unique_students, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nutritional-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_split(holdout, df):\n",
    "    test = df[df.student_user_xid.isin(students_tenfold[holdout])]\n",
    "    \n",
    "    train = students_tenfold[:holdout] + students_tenfold[holdout+1:]\n",
    "    train = [val for sublist in train for val in sublist]\n",
    "    train = df[df.student_user_xid.isin(train)]\n",
    "    \n",
    "    return (test, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-directory",
   "metadata": {},
   "source": [
    "# grouping timeseries by assignment_log_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "integrated-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = 24\n",
    "def create_xy(df):\n",
    "    groupeddf = df.groupby('assignment_log_id').agg(lambda x: x.tolist())\n",
    "    del groupeddf['student_user_xid']\n",
    "    \n",
    "    X = groupeddf.iloc[:,:-1].to_numpy()\n",
    "    y = groupeddf.iloc[:, -1:].to_numpy()\n",
    "    \n",
    "    XT = [np.array([np.array(xii) for xii in xi]).reshape((input_cols,-1)).T for xi in X]\n",
    "    yt = [np.array([np.array(yii) for yii in yi]).reshape((1,-1)).T for yi in y]\n",
    "    \n",
    "    return (XT, yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-smooth",
   "metadata": {},
   "source": [
    "# Create and run lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "advance-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 50\n",
    "n_epochs = 200\n",
    "batch_size = 64\n",
    "val_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "indonesian-corpus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "37/37 [==============================] - 8s 147ms/step - loss: 0.5228 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02067, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02067 to 0.01260, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01260 to 0.01082, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01082 to 0.00976, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00976 to 0.00935, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 5s 123ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00935 to 0.00914, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 5s 142ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00914 to 0.00865, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00865 to 0.00802, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 5s 147ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00802 to 0.00795, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00795 to 0.00764, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 5s 138ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00764\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 5s 130ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00764 to 0.00747, saving model to best_model.h5\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 5s 135ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00747 to 0.00728, saving model to best_model.h5\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 4s 106ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00728 to 0.00726, saving model to best_model.h5\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00726 to 0.00697, saving model to best_model.h5\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00697 to 0.00681, saving model to best_model.h5\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 7s 178ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00681 to 0.00671, saving model to best_model.h5\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 4s 115ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00671 to 0.00660, saving model to best_model.h5\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 4s 115ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00660\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 5s 132ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00660\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00660\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00660 to 0.00647, saving model to best_model.h5\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00647 to 0.00635, saving model to best_model.h5\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00635\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00635 to 0.00616, saving model to best_model.h5\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00616\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00616\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00616\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00616\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 4s 101ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00616\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 5s 126ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00616\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 5s 126ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00616 to 0.00596, saving model to best_model.h5\n",
      "Epoch 33/200\n",
      "37/37 [==============================] - 5s 131ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00596 to 0.00588, saving model to best_model.h5\n",
      "Epoch 34/200\n",
      "37/37 [==============================] - 7s 180ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00588 to 0.00550, saving model to best_model.h5\n",
      "Epoch 35/200\n",
      "37/37 [==============================] - 7s 195ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00550\n",
      "Epoch 36/200\n",
      "37/37 [==============================] - 5s 136ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00550\n",
      "Epoch 37/200\n",
      "37/37 [==============================] - 4s 120ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00550 to 0.00539, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "37/37 [==============================] - 4s 117ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00539 to 0.00527, saving model to best_model.h5\n",
      "Epoch 39/200\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00527 to 0.00493, saving model to best_model.h5\n",
      "Epoch 40/200\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00493 to 0.00486, saving model to best_model.h5\n",
      "Epoch 41/200\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00486 to 0.00485, saving model to best_model.h5\n",
      "Epoch 42/200\n",
      "37/37 [==============================] - 4s 114ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00485 to 0.00473, saving model to best_model.h5\n",
      "Epoch 43/200\n",
      "37/37 [==============================] - 4s 102ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00473\n",
      "Epoch 44/200\n",
      "37/37 [==============================] - 5s 136ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00473\n",
      "Epoch 45/200\n",
      "37/37 [==============================] - 4s 108ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00473 to 0.00471, saving model to best_model.h5\n",
      "Epoch 46/200\n",
      "37/37 [==============================] - 8s 212ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00471 to 0.00467, saving model to best_model.h5\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 7s 186ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00467\n",
      "Epoch 48/200\n",
      "37/37 [==============================] - 5s 133ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00467 to 0.00449, saving model to best_model.h5\n",
      "Epoch 49/200\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00449 to 0.00425, saving model to best_model.h5\n",
      "Epoch 50/200\n",
      "37/37 [==============================] - 6s 175ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00425\n",
      "Epoch 51/200\n",
      "37/37 [==============================] - 6s 175ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00425\n",
      "Epoch 52/200\n",
      "37/37 [==============================] - 5s 142ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00425\n",
      "Epoch 53/200\n",
      "37/37 [==============================] - 6s 157ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00425\n",
      "Epoch 54/200\n",
      "37/37 [==============================] - 10s 276ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00425 to 0.00410, saving model to best_model.h5\n",
      "Epoch 55/200\n",
      "37/37 [==============================] - 5s 141ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00410 to 0.00409, saving model to best_model.h5\n",
      "Epoch 56/200\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00409\n",
      "Epoch 57/200\n",
      "37/37 [==============================] - 4s 118ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00409\n",
      "Epoch 58/200\n",
      "37/37 [==============================] - 5s 125ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00409\n",
      "Epoch 59/200\n",
      "37/37 [==============================] - 5s 122ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00409\n",
      "Epoch 60/200\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00409 to 0.00409, saving model to best_model.h5\n",
      "Epoch 61/200\n",
      "37/37 [==============================] - 4s 112ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00409\n",
      "Epoch 62/200\n",
      "37/37 [==============================] - 4s 114ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00409\n",
      "Epoch 63/200\n",
      "37/37 [==============================] - 4s 112ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00409\n",
      "Epoch 64/200\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00409 to 0.00396, saving model to best_model.h5\n",
      "Epoch 65/200\n",
      "37/37 [==============================] - 4s 116ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00396\n",
      "Epoch 66/200\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00396 to 0.00396, saving model to best_model.h5\n",
      "Epoch 67/200\n",
      "37/37 [==============================] - 4s 108ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00396\n",
      "Epoch 68/200\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00396\n",
      "Epoch 69/200\n",
      "37/37 [==============================] - 5s 131ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00396 to 0.00396, saving model to best_model.h5\n",
      "Epoch 70/200\n",
      "37/37 [==============================] - 5s 145ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00396 to 0.00393, saving model to best_model.h5\n",
      "Epoch 71/200\n",
      "37/37 [==============================] - 5s 132ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00393\n",
      "Epoch 72/200\n",
      "37/37 [==============================] - 6s 160ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00393\n",
      "Epoch 73/200\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00393\n",
      "Epoch 74/200\n",
      "37/37 [==============================] - 6s 149ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00393\n",
      "Epoch 75/200\n",
      "37/37 [==============================] - 4s 115ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00393\n",
      "Epoch 76/200\n",
      "37/37 [==============================] - 4s 119ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00393\n",
      "Epoch 77/200\n",
      "37/37 [==============================] - 5s 127ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00393\n",
      "Epoch 78/200\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00393\n",
      "Epoch 79/200\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00393\n",
      "Epoch 80/200\n",
      "37/37 [==============================] - 4s 121ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00393\n",
      "Epoch 00080: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 9s 162ms/step - loss: 0.5058 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02184, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0200 - val_loss: 0.0174\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02184 to 0.01740, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 5s 139ms/step - loss: 0.0167 - val_loss: 0.0156\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01740 to 0.01556, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 5s 142ms/step - loss: 0.0156 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01556 to 0.01351, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01351 to 0.01255, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 5s 142ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01255 to 0.01205, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 4s 124ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01205 to 0.01149, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 4s 107ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01149 to 0.01071, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 4s 105ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01071 to 0.01014, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 5s 131ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01014 to 0.00965, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 5s 140ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00965 to 0.00926, saving model to best_model.h5\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 5s 138ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00926 to 0.00896, saving model to best_model.h5\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 4s 118ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00896\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 4s 120ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00896 to 0.00840, saving model to best_model.h5\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 5s 147ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00840\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 5s 143ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00840 to 0.00771, saving model to best_model.h5\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 6s 162ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00771\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 4s 115ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00771\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 5s 140ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00771\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 4s 109ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00771\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 4s 107ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00771 to 0.00756, saving model to best_model.h5\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 4s 108ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00756 to 0.00714, saving model to best_model.h5\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 4s 110ms/step - loss: 0.0069 - val_loss: 0.0072: \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00714\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00714 to 0.00705, saving model to best_model.h5\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 4s 116ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00705\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 4s 109ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00705 to 0.00690, saving model to best_model.h5\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 4s 108ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00690 to 0.00662, saving model to best_model.h5\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 4s 109ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00662\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00662\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 4s 118ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00662 to 0.00644, saving model to best_model.h5\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 4s 115ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00644\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00644 to 0.00637, saving model to best_model.h5\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00637 to 0.00617, saving model to best_model.h5\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 5s 144ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00617 to 0.00604, saving model to best_model.h5\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 5s 128ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00604 to 0.00593, saving model to best_model.h5\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00593\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 5s 130ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00593\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 5s 146ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00593 to 0.00573, saving model to best_model.h5\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 5s 149ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00573 to 0.00547, saving model to best_model.h5\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 4s 124ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00547\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 4s 119ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00547 to 0.00529, saving model to best_model.h5\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 4s 114ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00529\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 4s 117ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00529\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 4s 110ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00529 to 0.00522, saving model to best_model.h5\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00522\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 4s 114ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00522\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 4s 112ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00522\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 5s 137ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00522\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 5s 139ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00522\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 4s 118ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00522 to 0.00512, saving model to best_model.h5\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 4s 116ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00512\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 4s 122ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00512\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 4s 125ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00512 to 0.00508, saving model to best_model.h5\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 5s 138ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00508\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 4s 116ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00508 to 0.00504, saving model to best_model.h5\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 5s 135ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00504 to 0.00500, saving model to best_model.h5\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00500 to 0.00470, saving model to best_model.h5\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 4s 111ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00470\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 4s 109ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00470\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00470\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 4s 111ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00470 to 0.00452, saving model to best_model.h5\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 4s 122ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00452 to 0.00448, saving model to best_model.h5\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 4s 111ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00448\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 4s 119ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00448 to 0.00443, saving model to best_model.h5\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 5s 131ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00443 to 0.00435, saving model to best_model.h5\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 4s 115ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00435\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 4s 110ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00435 to 0.00433, saving model to best_model.h5\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 4s 108ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00433\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 5s 131ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00433\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 4s 114ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00433\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 4s 107ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00433\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 4s 109ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00433 to 0.00429, saving model to best_model.h5\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 4s 109ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00429\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 4s 118ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00429 to 0.00426, saving model to best_model.h5\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00426\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 4s 111ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00426 to 0.00425, saving model to best_model.h5\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00425\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 4s 110ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00425\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 4s 111ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00425\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 4s 112ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00425\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00425 to 0.00419, saving model to best_model.h5\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 5s 143ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00419\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 5s 130ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00419\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00419\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 4s 105ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00419\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 4s 121ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00419\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00419\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00419\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 4s 112ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00419\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 4s 105ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00419\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 4s 107ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00419\n",
      "Epoch 00091: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 7s 118ms/step - loss: 0.5451 - val_loss: 0.0258\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02576, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02576 to 0.01212, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01212 to 0.01072, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01072 to 0.00970, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00970 to 0.00919, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00919 to 0.00889, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00889 to 0.00855, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00855 to 0.00820, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00820 to 0.00793, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00793 to 0.00773, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00773 to 0.00756, saving model to best_model.h5\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00756 to 0.00734, saving model to best_model.h5\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00734\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00734\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00734\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00734 to 0.00724, saving model to best_model.h5\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00724\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 5s 131ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00724\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00724 to 0.00703, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 5s 130ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00703\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00703 to 0.00697, saving model to best_model.h5\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00697 to 0.00688, saving model to best_model.h5\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00688 to 0.00681, saving model to best_model.h5\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00681 to 0.00652, saving model to best_model.h5\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00652 to 0.00648, saving model to best_model.h5\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00648 to 0.00640, saving model to best_model.h5\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0063 - val_loss: 0.0063oss: 0.006\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00640 to 0.00628, saving model to best_model.h5\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00628\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00628 to 0.00613, saving model to best_model.h5\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00613 to 0.00607, saving model to best_model.h5\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00607 to 0.00597, saving model to best_model.h5\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00597 to 0.00591, saving model to best_model.h5\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00591 to 0.00585, saving model to best_model.h5\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00585 to 0.00580, saving model to best_model.h5\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00580 to 0.00578, saving model to best_model.h5\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00578\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00578\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00578 to 0.00575, saving model to best_model.h5\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00575 to 0.00563, saving model to best_model.h5\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00563\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0055 - val_loss: 0.0058TA: 0s - lo\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00563\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00563 to 0.00562, saving model to best_model.h5\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00562 to 0.00561, saving model to best_model.h5\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00561 to 0.00546, saving model to best_model.h5\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00546 to 0.00528, saving model to best_model.h5\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00528 to 0.00524, saving model to best_model.h5\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00524\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00524 to 0.00496, saving model to best_model.h5\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00496\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00496\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00496\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00496\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00496 to 0.00494, saving model to best_model.h5\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00494 to 0.00487, saving model to best_model.h5\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0053 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00487\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00487\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00487\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0072 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00487\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00487\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00487\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00487\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00487\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00487\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0055 - val_loss: 0.0053los\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00487\n",
      "Epoch 00064: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 7s 130ms/step - loss: 0.5891 - val_loss: 0.0290\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02902, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 4s 118ms/step - loss: 0.0202 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02902 to 0.01298, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 4s 115ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01298 to 0.01155, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01155 to 0.01065, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01065 to 0.00996, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 4s 123ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00996 to 0.00947, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 4s 109ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00947 to 0.00908, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00908 to 0.00862, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 4s 108ms/step - loss: 0.0084 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00862 to 0.00862, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 4s 109ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00862 to 0.00809, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00809 to 0.00788, saving model to best_model.h5\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 4s 107ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00788 to 0.00770, saving model to best_model.h5\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 4s 109ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00770 to 0.00734, saving model to best_model.h5\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 4s 107ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00734\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 4s 109ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00734 to 0.00726, saving model to best_model.h5\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 4s 116ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00726 to 0.00715, saving model to best_model.h5\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 4s 117ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00715 to 0.00704, saving model to best_model.h5\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 4s 116ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00704 to 0.00695, saving model to best_model.h5\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 4s 117ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00695 to 0.00685, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00685 to 0.00664, saving model to best_model.h5\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00664 to 0.00655, saving model to best_model.h5\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00655\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00655 to 0.00644, saving model to best_model.h5\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00644 to 0.00624, saving model to best_model.h5\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 0.0055 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00624\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00624 to 0.00615, saving model to best_model.h5\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00615\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00615 to 0.00612, saving model to best_model.h5\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00612 to 0.00605, saving model to best_model.h5\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00605 to 0.00588, saving model to best_model.h5\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00588\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00588\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00588 to 0.00575, saving model to best_model.h5\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 4s 107ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00575 to 0.00569, saving model to best_model.h5\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 4s 108ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00569 to 0.00564, saving model to best_model.h5\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00564 to 0.00561, saving model to best_model.h5\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00561 to 0.00549, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 4s 115ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00549 to 0.00547, saving model to best_model.h5\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 4s 105ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00547 to 0.00544, saving model to best_model.h5\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00544 to 0.00540, saving model to best_model.h5\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 4s 106ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00540\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 4s 107ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00540 to 0.00534, saving model to best_model.h5\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00534 to 0.00534, saving model to best_model.h5\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00534 to 0.00525, saving model to best_model.h5\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00525 to 0.00522, saving model to best_model.h5\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00522 to 0.00502, saving model to best_model.h5\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 4s 116ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00502\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00502\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00502\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00502 to 0.00501, saving model to best_model.h5\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00501 to 0.00486, saving model to best_model.h5\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00486 to 0.00468, saving model to best_model.h5\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 4s 108ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00468\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 4s 105ms/step - loss: 0.0047 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00468\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 4s 105ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00468\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 4s 107ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00468\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00468\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 4s 108ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00468 to 0.00454, saving model to best_model.h5\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00454\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00454 to 0.00443, saving model to best_model.h5\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00443\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00443\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 4s 117ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00443\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00443 to 0.00443, saving model to best_model.h5\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00443\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 4s 115ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00443\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 6s 175ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00443\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 6s 170ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00443 to 0.00441, saving model to best_model.h5\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 8s 232ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00441\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00441\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 6s 162ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00441\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00441\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 5s 135ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00441\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00441 to 0.00426, saving model to best_model.h5\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.0043 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00426\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00426\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00426\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00426\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0061 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00426\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 4s 122ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00426\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 6s 183ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00426\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 6s 178ms/step - loss: 0.0050 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00426\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00426\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00426\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 9s 159ms/step - loss: 0.5365 - val_loss: 0.0369\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03687, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 5s 141ms/step - loss: 0.0339 - val_loss: 0.0281\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03687 to 0.02813, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 5s 130ms/step - loss: 0.0263 - val_loss: 0.0222\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02813 to 0.02222, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.0216 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02222 to 0.01964, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 5s 130ms/step - loss: 0.0193 - val_loss: 0.0176\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01964 to 0.01757, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 5s 145ms/step - loss: 0.0174 - val_loss: 0.0166\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01757 to 0.01656, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 5s 145ms/step - loss: 0.0167 - val_loss: 0.0161\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01656 to 0.01609, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01609 to 0.01502, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 5s 150ms/step - loss: 0.0146 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01502 to 0.01343, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 5s 135ms/step - loss: 0.0139 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01343 to 0.01272, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 5s 150ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01272 to 0.01211, saving model to best_model.h5\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 5s 155ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01211 to 0.01202, saving model to best_model.h5\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01202 to 0.01079, saving model to best_model.h5\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 4s 129ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01079\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01079 to 0.01007, saving model to best_model.h5\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 4s 126ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01007\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 4s 124ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01007 to 0.00981, saving model to best_model.h5\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00981 to 0.00971, saving model to best_model.h5\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00971 to 0.00928, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 4s 121ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00928 to 0.00853, saving model to best_model.h5\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 4s 120ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00853 to 0.00840, saving model to best_model.h5\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 4s 122ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00840 to 0.00823, saving model to best_model.h5\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 4s 126ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00823\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 4s 119ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00823 to 0.00816, saving model to best_model.h5\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00816 to 0.00811, saving model to best_model.h5\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00811 to 0.00787, saving model to best_model.h5\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00787 to 0.00778, saving model to best_model.h5\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 4s 121ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00778 to 0.00771, saving model to best_model.h5\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 4s 121ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00771 to 0.00726, saving model to best_model.h5\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 4s 125ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00726\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 4s 120ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00726\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 4s 120ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00726\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 5s 130ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00726\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 4s 124ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00726 to 0.00726, saving model to best_model.h5\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00726 to 0.00711, saving model to best_model.h5\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 4s 118ms/step - loss: 0.0070 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00711\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 4s 121ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00711 to 0.00696, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00696\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 5s 157ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00696\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 4s 127ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00696 to 0.00664, saving model to best_model.h5\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 4s 122ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00664 to 0.00664, saving model to best_model.h5\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00664\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00664\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00664\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 4s 125ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00664 to 0.00653, saving model to best_model.h5\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 4s 128ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00653 to 0.00640, saving model to best_model.h5\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 4s 120ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00640 to 0.00619, saving model to best_model.h5\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00619 to 0.00611, saving model to best_model.h5\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00611 to 0.00591, saving model to best_model.h5\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 4s 125ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00591 to 0.00565, saving model to best_model.h5\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 4s 121ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00565 to 0.00561, saving model to best_model.h5\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00561 to 0.00553, saving model to best_model.h5\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00553 to 0.00549, saving model to best_model.h5\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 5s 145ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00549\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 5s 150ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00549\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 5s 151ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00549\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 4s 123ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00549\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 5s 138ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00549 to 0.00531, saving model to best_model.h5\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 5s 137ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00531\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 4s 120ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00531 to 0.00525, saving model to best_model.h5\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00525\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00525 to 0.00520, saving model to best_model.h5\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00520\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 5s 138ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00520 to 0.00517, saving model to best_model.h5\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 5s 143ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00517\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 5s 158ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00517 to 0.00516, saving model to best_model.h5\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00516\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00516 to 0.00508, saving model to best_model.h5\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 4s 105ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00508\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 4s 106ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00508\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 4s 108ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00508 to 0.00496, saving model to best_model.h5\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 4s 109ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00496\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 3s 92ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00496\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 3s 94ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00496\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 4s 120ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00496\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 4s 111ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00496\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 3s 99ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00496\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 4s 112ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00496\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 4s 104ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00496\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 4s 107ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00496\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 3s 99ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00496\n",
      "Epoch 00081: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 8s 150ms/step - loss: 0.5599 - val_loss: 0.0387\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03869, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0278 - val_loss: 0.0167\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03869 to 0.01672, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0161 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01672 to 0.01377, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01377 to 0.01281, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01281 to 0.01146, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01146 to 0.01108, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01108 to 0.01063, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01063 to 0.01013, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01013 to 0.00970, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00970\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0106 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00970\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00970\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00970\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00970\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00970 to 0.00959, saving model to best_model.h5\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00959 to 0.00925, saving model to best_model.h5\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00925 to 0.00894, saving model to best_model.h5\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00894 to 0.00830, saving model to best_model.h5\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00830 to 0.00807, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00807 to 0.00806, saving model to best_model.h5\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00806\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0075 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00806 to 0.00766, saving model to best_model.h5\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00766 to 0.00726, saving model to best_model.h5\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00726\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00726 to 0.00698, saving model to best_model.h5\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00698\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00698 to 0.00673, saving model to best_model.h5\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0064 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00673\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00673 to 0.00669, saving model to best_model.h5\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00669\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00669 to 0.00642, saving model to best_model.h5\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00642\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00642 to 0.00612, saving model to best_model.h5\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00612\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00612\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00612\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00612 to 0.00597, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00597\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00597 to 0.00582, saving model to best_model.h5\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00582 to 0.00561, saving model to best_model.h5\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 5s 127ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00561 to 0.00553, saving model to best_model.h5\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00553 to 0.00548, saving model to best_model.h5\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00548 to 0.00540, saving model to best_model.h5\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00540 to 0.00540, saving model to best_model.h5\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00540 to 0.00520, saving model to best_model.h5\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00520\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00520 to 0.00519, saving model to best_model.h5\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00519 to 0.00512, saving model to best_model.h5\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00512 to 0.00506, saving model to best_model.h5\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00506 to 0.00486, saving model to best_model.h5\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00486 to 0.00474, saving model to best_model.h5\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00474\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00474\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00474\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00474\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00474 to 0.00470, saving model to best_model.h5\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00470 to 0.00468, saving model to best_model.h5\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00468 to 0.00465, saving model to best_model.h5\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00465\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00465 to 0.00450, saving model to best_model.h5\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00450\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00450\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00450 to 0.00441, saving model to best_model.h5\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00441\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00441\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00441\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00441\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00441\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00441\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00441 to 0.00427, saving model to best_model.h5\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00427\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00427 to 0.00427, saving model to best_model.h5\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00427\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00427 to 0.00418, saving model to best_model.h5\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00418\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00418\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00418\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00418\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00418\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00418 to 0.00417, saving model to best_model.h5\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00417\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00417\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00417\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00417\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00417\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00417 to 0.00408, saving model to best_model.h5\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00408\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00408 to 0.00403, saving model to best_model.h5\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00403\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00403\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00403\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00403\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00403\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00403\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00403\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00403\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00403\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00403 to 0.00401, saving model to best_model.h5\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00401\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00401\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00401\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00401 to 0.00393, saving model to best_model.h5\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00393\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00393\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00393\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00393\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00393\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00393\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00393\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00393\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00393\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00393\n",
      "Epoch 00112: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnB0lEQVR4nO3de5hdVZ3m8e+79zlVlfu1gpIQEzTaoEiiIWJr27aCBrEBWwVUemjHmeg88miPNiN0I470OINtP2rb0ghqpvEGInhJj7G5CHhDJOHSCgEkIJIKSEJC7qnLOfs3f+xdVacqJ1CVZKdSlffzPPXk7Gutk52c96y19l5LEYGZmdlgyUgXwMzMDk0OCDMza8oBYWZmTTkgzMysKQeEmZk15YAwM7OmHBBmB4Ckf5X0v4a472OSTtrf85iVzQFhZmZNOSDMzKwpB4QdNoqmnfMl/VrSTklflXSEpB9J2i7pZknTGvY/TdL9krZIuk3SMQ3bFkm6uzju20DboN/1Vkn3FsfeLunl+1jm/yppraTNklZIOrJYL0mfk7RB0jZJv5H0smLbWyStKcq2XtLf7NNfmB32HBB2uHk7cDLwYuDPgR8Bfwu0k/9/+BCApBcDVwN/XWxbCfybpBZJLcD3ga8D04HvFOelOHYRsBx4PzADuAJYIal1OAWV9Abg/wBnAs8Hfg9cU2x+E/C64n1MKfbZVGz7KvD+iJgEvAy4ZTi/16yXA8ION/8cEU9FxHrgZ8CvIuKeiOgEvgcsKvY7C/hhRNwUET3APwLjgD8GTgSqwOcjoicirgNWNfyOZcAVEfGriKhHxFVAV3HccLwHWB4Rd0dEF3Ah8GpJ84AeYBLwR4Ai4oGIeLI4rgc4VtLkiHgmIu4e5u81AxwQdvh5quH17ibLE4vXR5J/YwcgIjJgHTC72LY+Bo50+fuG1y8APlo0L22RtAU4qjhuOAaXYQd5LWF2RNwCfBG4DNgg6UpJk4td3w68Bfi9pJ9IevUwf68Z4IAw25snyD/ogbzNn/xDfj3wJDC7WNdrbsPrdcCnImJqw8/4iLh6P8swgbzJaj1ARHwhIl4JHEve1HR+sX5VRJwOzCJvCrt2mL/XDHBAmO3NtcCpkt4oqQp8lLyZ6Hbgl0AN+JCkqqS/AJY0HPtl4AOSXlV0Jk+QdKqkScMsw9XAeyUtLPov/jd5k9hjkk4ozl8FdgKdQFb0kbxH0pSiaWwbkO3H34MdxhwQZk1ExEPAOcA/A0+Td2j/eUR0R0Q38BfAXwGbyfsrvttw7Grgv5I3AT0DrC32HW4ZbgY+DlxPXmt5IXB2sXkyeRA9Q94MtQn4TLHtL4HHJG0DPkDel2E2bPKEQWZm1oxrEGZm1pQDwszMmnJAmJlZUw4IMzNrqjLSBThQZs6cGfPmzRvpYpiZjSp33XXX0xHR3mzbmAmIefPmsXr16pEuhpnZqCLp93vb5iYmMzNrygFhZmZNOSDMzKypMdMH0UxPTw8dHR10dnaOdFFK19bWxpw5c6hWqyNdFDMbI8Z0QHR0dDBp0iTmzZvHwIE3x5aIYNOmTXR0dDB//vyRLo6ZjRFjuomps7OTGTNmjOlwAJDEjBkzDouakpkdPGM6IIAxHw69Dpf3aWYHz5gPiOdSz4I/bO1kV3dtpItiZnZIKTUgJC2V9JCktZIuaLL9A5J+I+leST+XdGyxfp6k3cX6eyV9qawyRgQbtneyq7teyvm3bNnCv/zLvwz7uLe85S1s2bLlwBfIzGyISgsISSn5fLmnkE+J+K7eAGjwrYg4LiIWAv8AfLZh2yMRsbD4+UBZ5exT0rQYewuIWu3ZaywrV65k6tSp5RTKzGwIyryLaQmwNiIeBZB0DXA6sKZ3h4jY1rD/BEr7mN673rb7sn7xBRdcwCOPPMLChQupVqu0tbUxbdo0HnzwQX77299yxhlnsG7dOjo7O/nwhz/MsmXLgP6hQ3bs2MEpp5zCa1/7Wm6//XZmz57ND37wA8aNG1dSic3McmUGxGzyydt7dQCvGryTpA8CHwFagDc0bJov6R7yOXUvioifNTl2GbAMYO7cuYM3D/DJf7ufNU9sa7ptZ1eNlkpCNR1eherYIyfziT9/6bPuc+mll3Lfffdx7733ctttt3Hqqady33339d2Ounz5cqZPn87u3bs54YQTePvb386MGTMGnOPhhx/m6quv5stf/jJnnnkm119/Peecc86wympmNlwj3kkdEZdFxAuBjwEXFaufBOZGxCLy8PiWpMlNjr0yIhZHxOL29qaDER5ylixZMuBZhS984Qscf/zxnHjiiaxbt46HH354j2Pmz5/PwoULAXjlK1/JY489dpBKa2aHszJrEOuBoxqW5xTr9uYa4HKAiOgCuorXd0l6BHgxsM/Dte7tm35E8Jv1WzlichtHTG7b19MP2YQJE/pe33bbbdx888388pe/ZPz48bz+9a9v+ixDa2tr3+s0Tdm9e3fp5TQzK7MGsQpYIGm+pBbgbGBF4w6SFjQsngo8XKxvLzq5kXQ0sAB4tIxC9vVBlNQJMWnSJLZv395029atW5k2bRrjx4/nwQcf5I477iinEGZm+6C0GkRE1CSdB9wApMDyiLhf0iXA6ohYAZwn6SSgB3gGOLc4/HXAJZJ6gAz4QERsLqusQpTVTT1jxgxe85rX8LKXvYxx48ZxxBFH9G1bunQpX/rSlzjmmGN4yUtewoknnlhKGczM9oWirK/OB9nixYtj8IRBDzzwAMccc8xzHnvf+q3MmNjC86eM7juDhvp+zcx6SborIhY32zbindSHijGSk2ZmB4wDAvAwRmZme3JAQN4D4RqEmdkADggARBz8h7jNzA5pDgiKJibng5nZAA4IKPEmVzOz0csBAaDyAmJfh/sG+PznP8+uXbsOcInMzIbGAUHxoFxJvdQOCDMbrcoci2nUKLOJqXG475NPPplZs2Zx7bXX0tXVxdve9jY++clPsnPnTs4880w6Ojqo1+t8/OMf56mnnuKJJ57gz/7sz5g5cya33nprSSU0M2vu8AmIH10Af/hN001zemokCKrp8M75vOPglEufdZfG4b5vvPFGrrvuOu68804igtNOO42f/vSnbNy4kSOPPJIf/vCHQD5G05QpU/jsZz/LrbfeysyZM4dXLjOzA8BNTAfRjTfeyI033siiRYt4xStewYMPPsjDDz/Mcccdx0033cTHPvYxfvaznzFlypSRLqqZ2WFUg3iWb/pPbNhOmiTMnzlhr/scCBHBhRdeyPvf//49tt19992sXLmSiy66iDe+8Y1cfPHFpZbFzOy5uAYBgChr0MLG4b7f/OY3s3z5cnbs2AHA+vXr2bBhA0888QTjx4/nnHPO4fzzz+fuu+/e41gzs4Pt8KlBPIsyh2JqHO77lFNO4d3vfjevfvWrAZg4cSLf+MY3WLt2Leeffz5JklCtVrn88ssBWLZsGUuXLuXII490J7WZHXQe7ht4dOMOIuCFsyaWVbyDwsN9m9lwebjvIRgbMWlmduA4IOifdtTMzPqN+YAYShOahrjfoWy0l9/MDj1jOiDa2trYtGnTkD48R/PHa0SwadMm2traRrooZjaGlHoXk6SlwD8BKfCViLh00PYPAB8E6sAOYFlErCm2XQi8r9j2oYi4Ybi/f86cOXR0dLBx48Zn3W/Tjm5qWUZ98+j9gG1ra2POnDkjXQwzG0NKCwhJKXAZcDLQAayStKI3AArfiogvFfufBnwWWCrpWOBs4KXAkcDNkl4cEfXhlKFarTJ//vzn3O+8b93Nmie3cctHFw3n9GZmY1qZTUxLgLUR8WhEdAPXAKc37hAR2xoWJ9Df0nM6cE1EdEXE74C1xflKUUlEPRvNjUxmZgdemU1Ms4F1DcsdwKsG7yTpg8BHgBbgDQ3H3jHo2NlNjl0GLAOYO3fuPhc0TRJqdQeEmVmjEe+kjojLIuKFwMeAi4Z57JURsTgiFre3t+9zGdIE1yDMzAYpMyDWA0c1LM8p1u3NNcAZ+3jsfkmThLpvEzUzG6DMgFgFLJA0X1ILeafzisYdJC1oWDwVeLh4vQI4W1KrpPnAAuDOsgrqPggzsz2V1gcRETVJ5wE3kN/mujwi7pd0CbA6IlYA50k6CegBngHOLY69X9K1wBqgBnxwuHcwDUeaiFo9K+v0ZmajUqnPQUTESmDloHUXN7z+8LMc+yngU+WVrl/qGoSZ2R5GvJP6UFBJRM0BYWY2gAOCvAaRuZPazGwABwSuQZiZNeOAIL/NNQIyh4SZWR8HBPmDcoBrEWZmDRwQ5DUIwP0QZmYNHBDkfRDgGoSZWSMHBPldTAB1D9hnZtbHAUF/QNQyP01tZtbLAUFDDcJ9EGZmfRwQ9PdBeLgNM7N+DggampjcB2Fm1scBQUMTk2sQZmZ9HBC4D8LMrBkHBFApHpRzDcLMrJ8DAvdBmJk144DAfRBmZs04IGi4zdV9EGZmfRwQNNYg/CS1mVmvUgNC0lJJD0laK+mCJts/ImmNpF9L+rGkFzRsq0u6t/hZUWY5K+6DMDPbQ6WsE0tKgcuAk4EOYJWkFRGxpmG3e4DFEbFL0n8D/gE4q9i2OyIWllW+Ron7IMzM9lBmDWIJsDYiHo2IbuAa4PTGHSLi1ojYVSzeAcwpsTx75T4IM7M9lRkQs4F1Dcsdxbq9eR/wo4blNkmrJd0h6YwSytcn9XwQZmZ7KK2JaTgknQMsBv60YfULImK9pKOBWyT9JiIeGXTcMmAZwNy5c/f59/c9KOc+CDOzPmXWINYDRzUszynWDSDpJODvgNMioqt3fUSsL/58FLgNWDT42Ii4MiIWR8Ti9vb2fS5o4jmpzcz2UGZArAIWSJovqQU4GxhwN5KkRcAV5OGwoWH9NEmtxeuZwGuAxs7tA6riOanNzPZQWhNTRNQknQfcAKTA8oi4X9IlwOqIWAF8BpgIfEcSwOMRcRpwDHCFpIw8xC4ddPfTAeU+CDOzPZXaBxERK4GVg9Zd3PD6pL0cdztwXJlla1Txg3JmZnvwk9R4sD4zs2YcEHiwPjOzZhwQ+EE5M7NmHBC4BmFm1owDgv7bXN0HYWbWzwFB/4NyrkGYmfVzQNAw1Ib7IMzM+jggcB+EmVkzDgg8YZCZWTMOCBonDPKT1GZmvRwQhUoi90GYmTVwQBTSRB6sz8ysgQOiUEnkCYPMzBo4IAqJaxBmZgM4IAqVRJ4wyMysgQOikCaJaxBmZg0cEAX3QZiZDeSAKPguJjOzgRwQhdR9EGZmA5QaEJKWSnpI0lpJFzTZ/hFJayT9WtKPJb2gYdu5kh4ufs4ts5yQNzG5BmFm1q+0gJCUApcBpwDHAu+SdOyg3e4BFkfEy4HrgH8ojp0OfAJ4FbAE+ISkaWWVFfIahIfaMDPrV2YNYgmwNiIejYhu4Brg9MYdIuLWiNhVLN4BzClevxm4KSI2R8QzwE3A0hLLmvdBuJPazKxPmQExG1jXsNxRrNub9wE/2sdj95v7IMzMBqqMdAEAJJ0DLAb+dJjHLQOWAcydO3e/yuA+CDOzgcqsQawHjmpYnlOsG0DSScDfAadFRNdwjo2IKyNicUQsbm9v36/C5n0QDggzs15lBsQqYIGk+ZJagLOBFY07SFoEXEEeDhsaNt0AvEnStKJz+k3FutJUksR9EGZmDUprYoqImqTzyD/YU2B5RNwv6RJgdUSsAD4DTAS+Iwng8Yg4LSI2S/p78pABuCQiNpdVVoAk8ZzUZmaNSu2DiIiVwMpB6y5ueH3Ssxy7HFheXukGqiQJu3vqB+vXmZkd8obUxCTpw5ImK/dVSXdLelPZhTuYPNSGmdlAQ+2D+M8RsY28L2Aa8JfApaWVagRU/KCcmdkAQw0IFX++Bfh6RNzfsG5MSPygnJnZAEMNiLsk3UgeEDdImgSMqa/bnjDIzGygoXZSvw9YCDwaEbuKsZLeW1qpRoD7IMzMBhpqDeLVwEMRsaV46vkiYGt5xTr4Kn5QzsxsgKEGxOXALknHAx8FHgG+VlqpRoD7IMzMBhpqQNQiIshHY/1iRFwGTCqvWAef+yDMzAYaah/EdkkXkt/e+ieSEqBaXrEOvjRJ3AdhZtZgqDWIs4Au8uch/kA+eN5nSivVCHAfhJnZQEMKiCIUvglMkfRWoDMixlQfRD5h0Ji6c9fMbL8MdaiNM4E7gXcCZwK/kvSOMgt2sOUTBo10KczMDh1D7YP4O+CE3iG5JbUDN5PPIz0m5BMGuQZhZtZrqH0QyaD5GjYN49hRwRMGmZkNNNQaxL9LugG4ulg+i0HDeI92fpLazGygIQVERJwv6e3Aa4pVV0bE98or1sGXJiICsixIkjE1DqGZ2T4Z8oRBEXE9cH2JZRlRlSIU6hEkY2ugWjOzffKsASFpO9Cs3UVARMTkUko1AtIk71KpZ0E1HeHCmJkdAp41ICJiTA2n8WzSosvd/RBmZrkxdSfS/misQZiZWckBIWmppIckrZV0QZPtryvmt64NfvBOUl3SvcXPijLLCQ19EA4IMzNgGJ3UwyUpBS4DTgY6gFWSVkTEmobdHgf+CvibJqfYHRELyyrfYGkREH5YzswsV1pAAEuAtRHxKICka8iHC+8LiIh4rNg24p/KrkGYmQ1UZhPTbGBdw3JHsW6o2iStlnSHpDOa7SBpWbHP6o0bN+5HUel79sEBYWaWO5Q7qV8QEYuBdwOfl/TCwTtExJURsTgiFre3t+/XL3MNwsxsoDIDYj1wVMPynGLdkETE+uLPR4HbgEUHsnCD9fdBOCDMzKDcgFgFLJA0X1ILcDYwpLuRJE2T1Fq8nkk+xMeaZz9q/1R8m6uZ2QClBURE1IDzgBuAB4BrI+J+SZdIOg1A0gmSOsjnmbhC0v3F4ccAqyX9B3ArcOmgu58OuN4H5RwQZma5Mu9iIiJWMmjU14i4uOH1KvKmp8HH3Q4cV2bZBvODcmZmAx3KndQHVcV9EGZmAzggCmnfXUwj/kiGmdkhwQFR6LuLqe4ahJkZOCD6pA3zQZiZmQOijx+UMzMbyAFR8INyZmYDOSAKfU1M7oMwMwMcEH3cB2FmNpADouChNszMBnJAFNwHYWY2kAOi4AflzMwGckAU+m9zHeGCmJkdIhwQBdcgzMwGckAUPFifmdlADoiC56Q2MxvIAVHwUBtmZgM5IAqpA8LMbAAHRKH3QTn3QZiZ5RwQBdcgzMwGKjUgJC2V9JCktZIuaLL9dZLullST9I5B286V9HDxc26Z5QQHhJnZYKUFhKQUuAw4BTgWeJekYwft9jjwV8C3Bh07HfgE8CpgCfAJSdPKKitAkQ9uYjIzK5RZg1gCrI2IRyOiG7gGOL1xh4h4LCJ+DQx+Ou3NwE0RsTkingFuApaWWFYkUUnkB+XMzAplBsRsYF3Dckex7oAdK2mZpNWSVm/cuHGfC9orTeQahJlZYVR3UkfElRGxOCIWt7e37/f50kRkDggzM6DcgFgPHNWwPKdYV/ax+8w1CDOzfmUGxCpggaT5klqAs4EVQzz2BuBNkqYVndNvKtaVKu+DcECYmUGJARERNeA88g/2B4BrI+J+SZdIOg1A0gmSOoB3AldIur84djPw9+Qhswq4pFhXqjRJXIMwMytUyjx5RKwEVg5ad3HD61XkzUfNjl0OLC+zfIOlCe6DMDMrjOpO6gOt4hqEmVkfB0SD1H0QZmZ9HBANKr6LycysjwOiQeInqc3M+jggGvg2VzOzfg6IBu6DMDPr54Bo4D4IM7N+DogGiWsQZmZ9HBAN3AdhZtbPAdHAg/WZmfVzQDSoJIlrEGZmBQdEg8Q1CDOzPg6IBhVPGGRm1scB0cB9EGZm/RwQDSoeasPMrI8DooFrEGZm/RwQDVL3QZiZ9XFANHANwsysnwOigZ+kNjPrV2pASFoq6SFJayVd0GR7q6RvF9t/JWlesX6epN2S7i1+vlRmOXulnnLUzKxPpawTS0qBy4CTgQ5glaQVEbGmYbf3Ac9ExIsknQ18Gjir2PZIRCwsq3zNpAnugzAzK5RZg1gCrI2IRyOiG7gGOH3QPqcDVxWvrwPeKEkllulZVVyDMDPrU2ZAzAbWNSx3FOua7hMRNWArMKPYNl/SPZJ+IulPmv0CScskrZa0euPGjftdYE8YZGbW71DtpH4SmBsRi4CPAN+SNHnwThFxZUQsjojF7e3t+/1L8wmD/KCcmRmUGxDrgaMalucU65ruI6kCTAE2RURXRGwCiIi7gEeAF5dYViAfrM/5YGaWKzMgVgELJM2X1AKcDawYtM8K4Nzi9TuAWyIiJLUXndxIOhpYADxaYlkB1yDMzBqVdhdTRNQknQfcAKTA8oi4X9IlwOqIWAF8Ffi6pLXAZvIQAXgdcImkHiADPhARm8sqa680EVnkdzIlyYj1lZuZHRJKCwiAiFgJrBy07uKG153AO5scdz1wfZll67NzE/zic3DM6VSSqQDUI0hwQJjZ4e1Q7aQ+eCqt8MvLYO1NfbUG38lkZuaAgNaJMOulsO5OKg4IM7M+DgiAo06A9XeRFq1KfljOzMwBkZuzBLq2MXNXfqOUaxBmZg6I3FFLAJi17dcAvtXVzAwHRG760TB+BkdszQPC+WBm5oDISTDnBGZu+Q/ANQgzM3BA9JtzApN3/I4p7HAfhJkZDoh+RT/EomQtXTXXIMzMHBC9jnwFoYRXpmv519sfG+nSmJmNOAdEr9aJaNZLOXXqOq6+83HuefyZkS6RmdmIckA0OuoE5nc9wPMmVrjo+/e5L8LMDmsOiEbzXou6d/D9GZez9cm1LP/574hwSJjZ4anU0VxHnWPfBid3MOu2T3NL2y+46saT+NufHcesFy9h8fEv54T5M2irpiNdSjOzg0Jj5Rvy4sWLY/Xq1QfmZFvXU/v3vyV58N9Iog7AEzGdX8TxbGj/Y6bOXsARz5vDUUfNYfasdia2OmfNbHSSdFdELG62zZ9szUyZTeWsq6BnNzy1hu51q6msuYW3PvELxm26FTYB+UPX7IpWOjSFrel0tldnsqttFrVxs0gmtlOd1A613cTurdCzE9JWotJGklaoJlBNAraup+WZ3zJpVwfb06lsbj2SHW2zSScfQeu05zNh6hFMnNbO1OmzmDJlKhPbqkieq8LMyucaxHDUa/CHX9O95Qk2bniSLU8/Sc/Wp9DODbTs3sjkno1Mqz/NeDqHfsoQ6/U8NrXMZlK2lSPqTzIpdjTdtxYJ2xjPDk1kU+UItrbOpmvC86mOn0TruMlUWlrpyYJ6Bm3VhMltVSaNayGdMB1NbKcysZ10Yjst4ybQVk1JPWue2WHPNYgDJa3A7FfQMvsVzH4pzN7bft076dr6FNs2P0W1dQLjpkyntW0i9VoPPd276O7qprsedNWCyTOfz9xJk5nbeHznNmrbnmLLxg62b36Kzu2b6N7+NNmurdC5haRzC5M7n2D+rtuZunPLsN/GzmhlK1Va6aFVNXYynq3JFHamkxgXnUzIdpKQsbU6k+0tR1CvjCONWt7cllTIkhYirZIIUjJIKvRUJ9HTMoUkSanSQzVqZK2TqY2bCeNn0FJJaauIlDpZ9y7qXbtIE1FpaaVabYWWCfncHNVxpEpIE6ikKWoZR9oynpZxE0lbJ0ClLR8axcxK54AoQ8sEWtuPpr396AGr0+Kn7bmOb5tMpW0yM2ctYOZz7VvrJuvayZatz9Dd3UU1FS2J2N5VZ9OOLjbv2A27nyHd/TSV3U9T6XqGls7NRL2L3VmV3VmFSs92xvVsZlxtG09rKo8nE8kCJvc8zfQda2mJbmqk1ElJqNMSPVSokSHqJFSpM5mdtKq2z39lQ1VH1KhQJyUjyX+UkJGSKf+JhpvzetRCd9JGj1oRgRSAkEQgSFJQBZIKoeJcqlBL26il48iSVlRpgbRKQpBmXaRZD0mSoLRCogRl3VDvAYlIW8nSFkhaIE1RUi0CTZAkiAQlKia0zVBkkLZCdRxU2kiVkUYdRUZdCVmILKnk+6RVktou0q5tJLXd1NJx9FQmkCVV0noXqndB1IksCCBJK1RaWknTCvUQWZZRVxW1TiBpnURCnWptB2ltN1mljahOIEtboXtX3iQaQdY2BdqmkpBR6dlJpb6LetpGrTKBqLTRojqt9JAmoEpexqhnRK2TrNZNpC1QaUNpCy2pqCaQKsiyjIiMepa/zoA0SUgqVRIlRARZVidJUiotbfm5I4NaF2Q9+ReFShskFah1Qs8uyPIvMPk1HXyDpvJ1Uv7T23IS0b9OxXFJcSNKVsvPKUFShbSa//5aJ9S7+9clleLcSf46LdZntfzfRb27OFct/31Jmv+upAJpS74cWbE9K85bycvcew5i4PvoLWNEcUwK46cf8P9vpQaEpKXAP5F/Ln4lIi4dtL0V+BrwSvKW/bMi4rFi24XA+4A68KGIuKHMso5alRaSSgvTJ0wbsHoScGTJvzoiqGVBrR70ZBmdXbvoqdfyD+W6qO/eQrZ9I/Vdm+jqyeisBbUQaesE0tbx1DPo6uqk1t2JenaR9OwgrXVSjyALyOp1knon6v0A6N4JPTuJer34z1RDWQZRR1mNyPI/+/4zRdBCFy1Z/hOIjKT4cMiK/1zdJFHPa0hF5LRSYzLdjKObVrqpUqNVNeohOmmhRoqg2D/opkJPsa6Fnr6ame1d772A/oZ6YPyu7RjmX3DHAT9vaddHUgpcBpwMdACrJK2IiDUNu70PeCYiXiTpbODTwFmSjgXOBl5K/jl3s6QXRxS3FNkhQRLVVOR3/qbQNmXQHhOBOQe/YAdQRNBTD3bU6n3f4Qjormd01/JvwBJ9/TmdWZBlUM8y6vUa9Vo3EVF80cu/3dejntdeSMgkVOui3r2b6N5NTSn1SMgQqYKKgiSroayLqPeQpeOpt0yiXhlHNeukWttJmvWQVdqoJ60oyfuWJKjVanR3dVHr6SZNoZIkJFkPdO8kurZTJ6U7HU930kZS76Za30WadRHV8URlPABp9zbSrq3UldCVTKAnaaOSddOS7SKtd9IVKZ1ZhVoGSfSQ1LshSfOaQ1KlEj2kWRfUe+jOoCcj3zdJkYQSkSovb2QZkdWLmkBKKIGsTtS6oKczr92lrURSoZL1UM06UdToUhs9ainCPyOJWsP1g0SBoqg9RqDIyFD+E+Q1y8i/HIgMReS1G1LqJIggjXyppio9aqGuCgnFF4ushoj8C0NkJFkPSfRQo0IPFWpKyYoaeKC8/qsYcHymhBqVvOYXdSqRf9EJVagnlbxWHPkYcYoMERD1vOaMGDftecwv4d9/mQG+BFgbEY8CSLoGOB1oDIjTgf9ZvL4O+KLyW3ROB66JiC7gd5LWFuf7ZYnlNduDJFoqoqXiZ0rt8FPmv/rZwLqG5Q727Nft2yciasBWYMYQj0XSMkmrJa3euHHjASy6mZmN6q9FEXFlRCyOiMXt7e0jXRwzszGlzIBYDxzVsDynWNd0H0kVYAp5Z/VQjjUzsxKVGRCrgAWS5ktqIe90XjFonxXAucXrdwC3RP7k3grgbEmtkuYDC4A7SyyrmZkNUlondUTUJJ0H3EB+V9vyiLhf0iXA6ohYAXwV+HrRCb2ZPEQo9ruWvEO7BnzQdzCZmR1cHmrDzOww9mxDbYzqTmozMyuPA8LMzJoaM01MkjYCv9+PU8wEnj5AxTnUjNX3NlbfF/i9jVaj8b29ICKaPicwZgJif0lavbd2uNFurL63sfq+wO9ttBpr781NTGZm1pQDwszMmnJA9LtypAtQorH63sbq+wK/t9FqTL0390GYmVlTrkGYmVlTDggzM2vqsA8ISUslPSRpraQLRro8+0PSUZJulbRG0v2SPlysny7pJkkPF39Oe65zHaokpZLukfT/iuX5kn5VXL9vFwNDjjqSpkq6TtKDkh6Q9OqxcN0k/ffi3+J9kq6W1Daar5mk5ZI2SLqvYV3T66TcF4r3+WtJrxi5ku+bwzogGqZFPQU4FnhXMd3paFUDPhoRxwInAh8s3s8FwI8jYgHw42J5tPow8EDD8qeBz0XEi4BnyKexHY3+Cfj3iPgj4Hjy9ziqr5uk2cCHgMUR8TLyQTt7pxYerdfsX4Glg9bt7TqdQj4S9QJgGXD5QSrjAXNYBwQN06JGRDfQOy3qqBQRT0bE3cXr7eQfMrPJ39NVxW5XAWeMSAH3k6Q5wKnAV4plAW8gn64WRul7kzQFeB356MZERHdEbGFsXLcKMK6Y72U88CSj+JpFxE/JR55utLfrdDrwtcjdAUyV9PyDUtAD5HAPiCFNbToaSZoHLAJ+BRwREU8Wm/4AHDFS5dpPnwf+B5AVyzOALcV0tTB6r998YCPwf4vms69ImsAov24RsR74R+Bx8mDYCtzF2LhmjfZ2nUb958vhHhBjkqSJwPXAX0fEtsZtxYRMo+7eZklvBTZExF0jXZYSVIBXAJdHxCJgJ4Oak0bjdSva4k8nD8AjgQns2TwzpozG6/RsDveAGHNTm0qqkofDNyPiu8Xqp3qrtsWfG0aqfPvhNcBpkh4jbwp8A3m7/dSi+QJG7/XrADoi4lfF8nXkgTHar9tJwO8iYmNE9ADfJb+OY+GaNdrbdRr1ny+He0AMZVrUUaNok/8q8EBEfLZhU+PUrucCPzjYZdtfEXFhRMyJiHnk1+mWiHgPcCv5dLUwet/bH4B1kl5SrHoj+WyKo/26PQ6cKGl88W+z932N+ms2yN6u0wrgPxV3M50IbG1oihoVDvsnqSW9hbxtu3da1E+NbIn2naTXAj8DfkN/O/3fkvdDXAvMJR8S/cyIGNzRNmpIej3wNxHxVklHk9copgP3AOdERNcIFm+fSFpI3vneAjwKvJf8C9yovm6SPgmcRX6H3T3AfyFvhx+V10zS1cDryYf1fgr4BPB9mlynIhS/SN6stgt4b0SMqmkvD/uAMDOz5g73JiYzM9sLB4SZmTXlgDAzs6YcEGZm1pQDwszMmnJAmB0CJL2+d4Ras0OFA8LMzJpyQJgNg6RzJN0p6V5JVxTzU+yQ9Lli3oMfS2ov9l0o6Y5iLoDvNcwT8CJJN0v6D0l3S3phcfqJDXNCfLN40MpsxDggzIZI0jHkTwW/JiIWAnXgPeSD0K2OiJcCPyF/uhbga8DHIuLl5E+3967/JnBZRBwP/DH5SKeQj7771+RzkxxNPm6R2YipPPcuZlZ4I/BKYFXx5X4c+cBsGfDtYp9vAN8t5niYGhE/KdZfBXxH0iRgdkR8DyAiOgGK890ZER3F8r3APODnpb8rs71wQJgNnYCrIuLCASuljw/ab1/Hr2kcj6iO/3/aCHMTk9nQ/Rh4h6RZ0DcX8QvI/x/1jk76buDnEbEVeEbSnxTr/xL4STHTX4ekM4pztEoafzDfhNlQ+RuK2RBFxBpJFwE3SkqAHuCD5BP8LCm2bSDvp4B86OcvFQHQO0Ir5GFxhaRLinO88yC+DbMh82iuZvtJ0o6ImDjS5TA70NzEZGZmTbkGYWZmTbkGYWZmTTkgzMysKQeEmZk15YAwM7OmHBBmZtbU/wcMlpJ9Yt+67gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 5s 93ms/step - loss: 0.5013 - val_loss: 0.0250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02503, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 3s 96ms/step - loss: 0.0211 - val_loss: 0.0167\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02503 to 0.01673, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 3s 85ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01673 to 0.01445, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 3s 95ms/step - loss: 0.0139 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01445 to 0.01325, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 3s 91ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01325 to 0.01207, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 3s 83ms/step - loss: 0.0120 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01207\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 3s 85ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01207 to 0.01133, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 3s 88ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01133 to 0.01060, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 3s 85ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01060 to 0.00995, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 3s 88ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00995 to 0.00928, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 3s 90ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00928 to 0.00907, saving model to best_model.h5\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00907\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00907 to 0.00883, saving model to best_model.h5\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 3s 89ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00883\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 3s 89ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00883 to 0.00860, saving model to best_model.h5\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 3s 88ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00860 to 0.00804, saving model to best_model.h5\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 3s 98ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00804 to 0.00782, saving model to best_model.h5\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 3s 98ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00782 to 0.00764, saving model to best_model.h5\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 3s 95ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00764 to 0.00747, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 3s 87ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00747 to 0.00730, saving model to best_model.h5\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 3s 95ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00730 to 0.00716, saving model to best_model.h5\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 4s 107ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00716 to 0.00703, saving model to best_model.h5\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 3s 94ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00703 to 0.00689, saving model to best_model.h5\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 4s 126ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00689 to 0.00679, saving model to best_model.h5\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00679 to 0.00663, saving model to best_model.h5\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 3s 100ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00663 to 0.00657, saving model to best_model.h5\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 3s 92ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00657 to 0.00649, saving model to best_model.h5\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 3s 98ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00649 to 0.00632, saving model to best_model.h5\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 3s 98ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00632 to 0.00628, saving model to best_model.h5\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 3s 97ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00628 to 0.00613, saving model to best_model.h5\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 4s 125ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00613 to 0.00606, saving model to best_model.h5\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 3s 101ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00606 to 0.00593, saving model to best_model.h5\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 3s 102ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00593\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00593 to 0.00575, saving model to best_model.h5\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00575\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 4s 106ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00575 to 0.00571, saving model to best_model.h5\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00571 to 0.00557, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00557\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00557 to 0.00547, saving model to best_model.h5\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 4s 115ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00547\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 3s 103ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00547 to 0.00532, saving model to best_model.h5\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 4s 115ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00532 to 0.00516, saving model to best_model.h5\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 4s 119ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00516 to 0.00507, saving model to best_model.h5\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00507\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 4s 119ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00507\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 12s 342ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00507\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 6s 178ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00507\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00507\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00507\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 4s 109ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00507\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 4s 108ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00507 to 0.00475, saving model to best_model.h5\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00475\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 6s 168ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00475\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 4s 104ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00475 to 0.00456, saving model to best_model.h5\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 4s 105ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00456\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00456\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 4s 111ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00456\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 4s 108ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00456\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 4s 105ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00456\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 4s 105ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00456\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 3s 101ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00456\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 3s 101ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00456\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00456\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 3s 103ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00456\n",
      "Epoch 00064: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 7s 128ms/step - loss: 0.5032 - val_loss: 0.0233\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02331, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0196 - val_loss: 0.0154\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02331 to 0.01543, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0151 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01543 to 0.01318, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01318 to 0.01162, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01162 to 0.01059, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01059 to 0.01014, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0105 - val_loss: 0.0096: 0 - ETA: 0s - los\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01014 to 0.00955, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00955\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00955 to 0.00923, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00923 to 0.00885, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00885\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00885\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00885 to 0.00839, saving model to best_model.h5\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00839 to 0.00801, saving model to best_model.h5\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00801\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00801 to 0.00776, saving model to best_model.h5\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00776 to 0.00744, saving model to best_model.h5\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00744\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00744 to 0.00729, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00729 to 0.00702, saving model to best_model.h5\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 5s 129ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00702 to 0.00674, saving model to best_model.h5\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00674\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00674 to 0.00651, saving model to best_model.h5\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00651\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0060 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00651 to 0.00642, saving model to best_model.h5\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00642 to 0.00634, saving model to best_model.h5\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00634 to 0.00624, saving model to best_model.h5\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00624 to 0.00615, saving model to best_model.h5\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00615 to 0.00607, saving model to best_model.h5\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00607 to 0.00591, saving model to best_model.h5\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00591\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00591 to 0.00579, saving model to best_model.h5\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00579 to 0.00572, saving model to best_model.h5\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00572\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00572\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00572\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 5s 152ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00572 to 0.00539, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00539 to 0.00508, saving model to best_model.h5\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00508\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00508\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 5s 131ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00508\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00508\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00508 to 0.00499, saving model to best_model.h5\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00499\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00499 to 0.00498, saving model to best_model.h5\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00498 to 0.00494, saving model to best_model.h5\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00494 to 0.00487, saving model to best_model.h5\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 5s 154ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00487 to 0.00483, saving model to best_model.h5\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00483 to 0.00472, saving model to best_model.h5\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00472 to 0.00471, saving model to best_model.h5\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00471 to 0.00448, saving model to best_model.h5\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00448\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00448\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 5s 127ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00448 to 0.00438, saving model to best_model.h5\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00438\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00438\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00438\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00438\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00438\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00438\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00438 to 0.00435, saving model to best_model.h5\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00435\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00435\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00435 to 0.00428, saving model to best_model.h5\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00428\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00428\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00428 to 0.00422, saving model to best_model.h5\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00422\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00422\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00422 to 0.00407, saving model to best_model.h5\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00407\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00407\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00407\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00407\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00407 to 0.00406, saving model to best_model.h5\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00406\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00406\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00406\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00406\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00406\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00406\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00406\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00406\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00406\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00406\n",
      "Epoch 00085: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 5s 99ms/step - loss: 0.5718 - val_loss: 0.0326\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03262, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0245 - val_loss: 0.0163\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03262 to 0.01634, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01634 to 0.01492, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0144 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01492 to 0.01332, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01332 to 0.01233, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01233 to 0.01194, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01194 to 0.01126, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01126 to 0.01073, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01073 to 0.01029, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01029 to 0.00958, saving model to best_model.h5\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00958 to 0.00925, saving model to best_model.h5\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00925 to 0.00898, saving model to best_model.h5\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00898\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00898 to 0.00851, saving model to best_model.h5\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00851 to 0.00812, saving model to best_model.h5\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00812\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00812\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00812 to 0.00810, saving model to best_model.h5\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00810 to 0.00764, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00764\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00764 to 0.00724, saving model to best_model.h5\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00724\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00724\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00724 to 0.00710, saving model to best_model.h5\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00710\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00710\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00710\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00710 to 0.00669, saving model to best_model.h5\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00669\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00669\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00669 to 0.00655, saving model to best_model.h5\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00655\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00655 to 0.00636, saving model to best_model.h5\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00636\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00636 to 0.00629, saving model to best_model.h5\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00629\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00629 to 0.00620, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00620\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00620\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00620\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00620 to 0.00616, saving model to best_model.h5\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00616 to 0.00604, saving model to best_model.h5\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00604 to 0.00591, saving model to best_model.h5\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00591 to 0.00550, saving model to best_model.h5\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00550 to 0.00549, saving model to best_model.h5\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00549 to 0.00548, saving model to best_model.h5\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00548 to 0.00543, saving model to best_model.h5\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00543 to 0.00527, saving model to best_model.h5\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00527\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00527\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00527\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00527\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00527\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00527\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00527 to 0.00502, saving model to best_model.h5\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00502\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00502 to 0.00492, saving model to best_model.h5\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00492\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00492 to 0.00482, saving model to best_model.h5\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00482\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00482 to 0.00471, saving model to best_model.h5\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00471\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00471 to 0.00469, saving model to best_model.h5\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00469 to 0.00464, saving model to best_model.h5\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00464\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00464 to 0.00460, saving model to best_model.h5\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00460 to 0.00460, saving model to best_model.h5\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00460 to 0.00458, saving model to best_model.h5\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00458 to 0.00451, saving model to best_model.h5\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00451 to 0.00446, saving model to best_model.h5\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00446 to 0.00439, saving model to best_model.h5\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00439\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00439\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00439\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00439 to 0.00437, saving model to best_model.h5\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00437 to 0.00431, saving model to best_model.h5\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00431\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00431 to 0.00431, saving model to best_model.h5\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00431\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00431\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00431\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00431\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00431\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00431\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00431\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00431\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00431\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00431\n",
      "Epoch 00088: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnAklEQVR4nO3de5xdZX3v8c93rb3nloRcBzQJkAjRglqDjHi3VkGDKNCqgIovbDmNnpe8pEfrEVrBIx57qPZlrRUVFHqsFxBBa3qM5aLgpQpkuFQIlyYgkgm3kCvJZC5779/5Y62ZrBl2ksllZZLM9/16bdnrtueZ7c589/M863keRQRmZmajJeNdADMz2z85IMzMrCkHhJmZNeWAMDOzphwQZmbWlAPCzMyackCY7QWS/q+k/z3Gcx+VdOKevo5Z2RwQZmbWlAPCzMyackDYhJE37Xxc0m8lbZF0paTDJP1E0rOSbpY0vXD+qZKWS9og6VZJxxSOHSfprvy67wFto37W2yXdk1/7a0l/uJtl/gtJKyWtk7RE0ux8vyT9g6SnJW2SdK+kl+TH3ibp/rxsqyX91W69YTbhOSBsonkncBLwQuAdwE+AvwY6yf49fARA0guBq4G/zI8tBf5NUoukFuBfgW8BM4Dv569Lfu1xwFXAB4GZwOXAEkmtu1JQSW8C/g9wBvB84PfANfnhtwBvyH+Pqfk5a/NjVwIfjIgpwEuAn+3KzzUb4oCwieafIuKpiFgN/BK4PSLujog+4IfAcfl5ZwI/joibImIQ+HugHXgN8CqgCnwxIgYj4jpgWeFnLAYuj4jbI6IeEd8E+vPrdsX7gKsi4q6I6AcuBF4taR4wCEwB/gBQRDwQEU/k1w0Cx0o6JCLWR8Rdu/hzzQAHhE08TxWeb22yPTl/PpvsGzsAEdEAVgFz8mOrY+RMl78vPD8S+FjevLRB0gbg8Py6XTG6DJvJaglzIuJnwJeBy4CnJV0h6ZD81HcCbwN+L+nnkl69iz/XDHBAmG3P42R/6IGszZ/sj/xq4AlgTr5vyBGF56uAz0bEtMKjIyKu3sMyTCJrsloNEBFfiojjgWPJmpo+nu9fFhGnAYeSNYVdu4s/1wxwQJhtz7XAKZLeLKkKfIysmejXwG+AGvARSVVJfwqcULj268CHJL0y70yeJOkUSVN2sQxXA38maWHef/G3ZE1ij0p6Rf76VWAL0Ac08j6S90mamjeNbQIae/A+2ATmgDBrIiIeAs4G/gl4hqxD+x0RMRARA8CfAh8A1pH1V/ygcG038BdkTUDrgZX5ubtahpuBi4DryWotRwFn5YcPIQui9WTNUGuBz+fH3g88KmkT8CGyvgyzXSYvGGRmZs24BmFmZk05IMzMrCkHhJmZNeWAMDOzpirjXYC9ZdasWTFv3rzxLoaZ2QHlzjvvfCYiOpsdO2gCYt68eXR3d493MczMDiiSfr+9Y25iMjOzphwQZmbWlAPCzMyaOmj6IJoZHBykp6eHvr6+8S5K6dra2pg7dy7VanW8i2JmB4mDOiB6enqYMmUK8+bNY+TEmweXiGDt2rX09PQwf/788S6OmR0kDuompr6+PmbOnHlQhwOAJGbOnDkhakpmtu8c1AEBHPThMGSi/J5mtu8c9AGxM/VG8OTGPnoHauNdFDOz/cqED4iI4Oln++gdqJfy+hs2bOArX/nKLl/3tre9jQ0bNuz9ApmZjdGED4ihlpmylsXYXkDUajuusSxdupRp06aVUygzszE4qO9iGpuhtvtyEuKCCy7g4YcfZuHChVSrVdra2pg+fToPPvgg//Vf/8Xpp5/OqlWr6Ovr4/zzz2fx4sXAtqlDNm/ezMknn8zrXvc6fv3rXzNnzhx+9KMf0d7eXkp5zcyGTJiA+PS/Lef+xzc1Pbalv0ZLJaGa7lqF6tjZh/Cpd7x4h+dceuml3Hfffdxzzz3ceuutnHLKKdx3333Dt6NeddVVzJgxg61bt/KKV7yCd77zncycOXPEa6xYsYKrr76ar3/965xxxhlcf/31nH322btUVjOzXTVhAmJ/ccIJJ4wYq/ClL32JH/7whwCsWrWKFStWPCcg5s+fz8KFCwE4/vjjefTRR/dVcc1sApswAbGjb/r39mykc0orz5vaVno5Jk2aNPz81ltv5eabb+Y3v/kNHR0dvPGNb2w6lqG1tXX4eZqmbN26tfRymplN+E5qAARRUh/ElClTePbZZ5se27hxI9OnT6ejo4MHH3yQ2267rZQymJntjglTg9gRUd5dTDNnzuS1r30tL3nJS2hvb+ewww4bPrZo0SK+9rWvccwxx/CiF72IV73qVeUUwsxsNyjK+su4j3V1dcXoBYMeeOABjjnmmJ1eu/zxjUzvaGH2tAP7zqCx/r5mZkMk3RkRXc2OuYkJEOJgCUozs73FAUE2WM7xYGY2kgOCcvsgzMwOVA4IXIMwM2um1ICQtEjSQ5JWSrqgyfEPSbpX0j2SfiXp2Hz/PElb8/33SPpameXEfRBmZs9R2m2uklLgMuAkoAdYJmlJRNxfOO27EfG1/PxTgS8Ai/JjD0fEwrLKN7Ks++KnmJkdWMqsQZwArIyIRyJiALgGOK14QkQUJ0eaxDi19JTZB7G7030DfPGLX6S3t3cvl8jMbGzKDIg5wKrCdk++bwRJH5b0MPA54COFQ/Ml3S3p55Je3+wHSFosqVtS95o1a3a7oJJKSyYHhJkdqMZ9JHVEXAZcJum9wCeBc4AngCMiYq2k44F/lfTiUTUOIuIK4ArIBsrtbhmyGkT5032fdNJJHHrooVx77bX09/fzJ3/yJ3z6059my5YtnHHGGfT09FCv17nooot46qmnePzxx/njP/5jZs2axS233FJK+czMtqfMgFgNHF7Ynpvv255rgK8CREQ/0J8/vzOvYbwQ6N7+5TvxkwvgyXubHpo9mK8mV0137TWf91I4+dIdnlKc7vvGG2/kuuuu44477iAiOPXUU/nFL37BmjVrmD17Nj/+8Y+BbI6mqVOn8oUvfIFbbrmFWbNm7Vq5zMz2gjKbmJYBCyTNl9QCnAUsKZ4gaUFh8xRgRb6/M+/kRtILgAXAIyWWdZ+48cYbufHGGznuuON4+ctfzoMPPsiKFSt46Utfyk033cQnPvEJfvnLXzJ16tTxLqqZWXk1iIioSToPuAFIgasiYrmkS4DuiFgCnCfpRGAQWE/WvATwBuASSYNAA/hQRKzbowLt4Jv+k89sodZosODQKXv0I3YmIrjwwgv54Ac/+Jxjd911F0uXLuWTn/wkb37zm7n44otLLYuZ2c6U2gcREUuBpaP2XVx4fv52rrseuL7MshUJSrt/qjjd91vf+lYuuugi3ve+9zF58mRWr15NtVqlVqsxY8YMzj77bKZNm8Y3vvGNEde6icnMxsO4d1LvD8ocSV2c7vvkk0/mve99L69+9asBmDx5Mt/+9rdZuXIlH//4x0mShGq1yle/+lUAFi9ezKJFi5g9e7Y7qc1sn/N038Bja3vZOljnRc8rt4mpbJ7u28x2laf73gmVuKKcmdmBygGRO0gqUmZme81BHxBjaUI7GGZzPViaCs1s/3FQB0RbWxtr167d6R9PSQd0FSIiWLt2LW1tbeNdFDM7iBzUdzHNnTuXnp4edjZP04beQXoHamjjgbsmdVtbG3Pnzh3vYpjZQeSgDohqtcr8+fN3et7fLn2Ab/3mcR74zKKdnmtmNlEc1E1MY1VJRK3RGO9imJntVxwQQCVNGKyHO3rNzAocEGQ1CIB6wwFhZjbEAQFU0iwgag4IM7NhDgigmmRvgwPCzGwbBwSFGkTdHdVmZkMcEGzrg3ANwsxsGwcE2V1MALW6A8LMbIgDgm01iEE3MZmZDSs1ICQtkvSQpJWSLmhy/EOS7pV0j6RfSTq2cOzC/LqHJL21zHJWU3dSm5mNVlpASEqBy4CTgWOB9xQDIPfdiHhpRCwEPgd8Ib/2WOAs4MXAIuAr+euVIh0eB+EahJnZkDJrECcAKyPikYgYAK4BTiueEBGbCpuT2Dbr9mnANRHRHxG/A1bmr1eKajrUxOQahJnZkDIn65sDrCps9wCvHH2SpA8DHwVagDcVrr1t1LVzmly7GFgMcMQRR+x2QSuJO6nNzEYb907qiLgsIo4CPgF8chevvSIiuiKiq7Ozc7fLMDQOYtBNTGZmw8oMiNXA4YXtufm+7bkGOH03r90jQzUIz8VkZrZNmQGxDFggab6kFrJO5yXFEyQtKGyeAqzIny8BzpLUKmk+sAC4o6yCDtcgfJurmdmw0vogIqIm6TzgBiAFroqI5ZIuAbojYglwnqQTgUFgPXBOfu1ySdcC9wM14MMRUS+rrNXhqTZcgzAzG1LqinIRsRRYOmrfxYXn5+/g2s8Cny2vdNsMd1K7D8LMbNi4d1LvD4bGQbgGYWa2jQMCj6Q2M2vGAYE7qc3MmnFAUFgwyE1MZmbDHBBAmnpNajOz0RwQQDXxSGozs9EcEHjBIDOzZhwQbLvN1Z3UZmbbOCDYNpLafRBmZts4ICiOpHZAmJkNcUDgNanNzJpxQABJIhK5k9rMrMgBkaukiZuYzMwKHBC5aiJqbmIyMxvmgMi5BmFmNpIDIldJ5E5qM7MCB0SuksrjIMzMCkoNCEmLJD0kaaWkC5oc/6ik+yX9VtJPJR1ZOFaXdE/+WDL62r2tkiQM+i4mM7NhpS05KikFLgNOAnqAZZKWRMT9hdPuBroiolfSfwc+B5yZH9saEQvLKt9o1VRectTMrKDMGsQJwMqIeCQiBoBrgNOKJ0TELRHRm2/eBswtsTw7lCbyOAgzs4IyA2IOsKqw3ZPv255zgZ8UttskdUu6TdLpzS6QtDg/p3vNmjV7VNhqmrgGYWZWUFoT066QdDbQBfxRYfeREbFa0guAn0m6NyIeLl4XEVcAVwB0dXXt0df/SuoahJlZUZk1iNXA4YXtufm+ESSdCPwNcGpE9A/tj4jV+X8fAW4FjiuxrFknte9iMjMbVmZALAMWSJovqQU4CxhxN5Kk44DLycLh6cL+6ZJa8+ezgNcCxc7tva7ikdRmZiOU1sQUETVJ5wE3AClwVUQsl3QJ0B0RS4DPA5OB70sCeCwiTgWOAS6X1CALsUtH3f2011VSeSS1mVlBqX0QEbEUWDpq38WF5ydu57pfAy8ts2yjVdOELf21ffkjzcz2ax5JnaskrkGYmRU5IHKpR1KbmY3ggMhVU1H3OAgzs2EOiFwlTTwOwsyswAGRqyZi0DUIM7NhDohcmoi6axBmZsMcELlK6pHUZmZFDohcNfVIajOzIgdEztN9m5mN5IDIZdN9OyDMzIY4IHLZSGo3MZmZDXFA5CppNpI6wrUIMzNwQAyrJAKg7mYmMzPAATGskmYB4X4IM7OMAyJXTbK3wgFhZpZxQOSGaxAeC2FmBjgghg31QXjKbzOzjAMiV0mzt8Kd1GZmmVIDQtIiSQ9JWinpgibHPyrpfkm/lfRTSUcWjp0jaUX+OKfMckKxBuEmJjMzGGNASDpf0iHKXCnpLklv2ck1KXAZcDJwLPAeSceOOu1uoCsi/hC4Dvhcfu0M4FPAK4ETgE9Jmr4rv9iuqqbupDYzKxprDeLPI2IT8BZgOvB+4NKdXHMCsDIiHomIAeAa4LTiCRFxS0T05pu3AXPz528FboqIdRGxHrgJWDTGsu6WNHEntZlZ0VgDQvl/3wZ8KyKWF/ZtzxxgVWG7J9+3PecCP9mVayUtltQtqXvNmjU7Kc6OVT0OwsxshLEGxJ2SbiQLiBskTQH22ldtSWcDXcDnd+W6iLgiIroioquzs3OPylAZGgfhu5jMzACojPG8c4GFwCMR0Zv3EfzZTq5ZDRxe2J6b7xtB0onA3wB/FBH9hWvfOOraW8dY1t0yNA7Cy46amWXGWoN4NfBQRGzIv+1/Eti4k2uWAQskzZfUApwFLCmeIOk44HLg1Ih4unDoBuAtkqbnndNvyfeVxjUIM7ORxhoQXwV6Jb0M+BjwMPAvO7ogImrAeWR/2B8Aro2I5ZIukXRqftrngcnA9yXdI2lJfu064DNkIbMMuCTfV5ptczG5BmFmBmNvYqpFREg6DfhyRFwp6dydXRQRS4Glo/ZdXHh+4g6uvQq4aozl22PDndSuQZiZAWMPiGclXUh2e+vrJSVAtbxi7XvDTUyuQZiZAWNvYjoT6CcbD/EkWafxLt1xtL9LPReTmdkIYwqIPBS+A0yV9HagLyJ22AdxoKl6LiYzsxHGOtXGGcAdwLuBM4DbJb2rzILta8O3uXoktZkZMPY+iL8BXjF0K6qkTuBmsvmTDgqVxJ3UZmZFY+2DSEaNU1i7C9ceECqpO6nNzIrGWoP4d0k3AFfn22cy6vbVA1018VxMZmZFYwqIiPi4pHcCr813XRERPyyvWPvecA3CTUxmZsDYaxBExPXA9SWWZVylXjDIzGyEHQaEpGeBZl+pBUREHFJKqcaBp/s2MxtphwEREVP2VUHG29BIao+DMDPLHFR3Iu0Jr0ltZjaSAyKXJCKRO6nNzIY4IAoqaeIFg8zMcg6Igmoi6q5BmJkBDogRKmniu5jMzHIOiIJKIndSm5nlSg0ISYskPSRppaQLmhx/g6S7JNVGzw4rqZ4vQzq8FGnZKql8m6uZWW7MI6l3laQUuAw4CegBlklaEhH3F057DPgA8FdNXmJrRCwsq3zNVJLECwaZmeVKCwjgBGBlRDwCIOka4DRgOCAi4tH82H7RrlNN5dlczcxyZTYxzQFWFbZ78n1j1SapW9Jtkk5vdoKkxfk53WvWrNmDombSRB4HYWaW2587qY+MiC7gvcAXJR01+oSIuCIiuiKiq7Ozc49/YDVNXIMwM8uVGRCrgcML23PzfWMSEavz/z4C3AoctzcL10wldQ3CzGxImQGxDFggab6kFuAsYEx3I0maLqk1fz6LbB2K+3d81Z6rJAmDvovJzAwoMSAiogacB9wAPABcGxHLJV0i6VQASa+Q1AO8G7hc0vL88mOAbkn/CdwCXDrq7qdSVBJR8zgIMzOg3LuYiIiljFqaNCIuLjxfRtb0NPq6XwMvLbNszVRSeSS1mVluf+6k3ueqaeIahJlZzgFRkCauQZiZDXFAFHgktZnZNg6Igmoq6h4HYWYGOCBGqKSJx0GYmeUcEAWVRF5Rzsws54AoqHguJjOzYQ6IAq8oZ2a2jQOioJp6JLWZ2RAHRIGn+zYz28YBUVBNE3dSm5nlHBAFlcRrUpuZDXFAFFTSbCR1hEPCzMwBUVBJBOBahJkZDogRKmkWEL7V1czMATFCNcneDgeEmZkDYoThGoTHQpiZlRsQkhZJekjSSkkXNDn+Bkl3SapJeteoY+dIWpE/zimznEOG+iA85beZWYkBISkFLgNOBo4F3iPp2FGnPQZ8APjuqGtnAJ8CXgmcAHxK0vSyyjqkkg41MbkGYWZWZg3iBGBlRDwSEQPANcBpxRMi4tGI+C0w+i/yW4GbImJdRKwHbgIWlVhWYFsNwqOpzczKDYg5wKrCdk++b69dK2mxpG5J3WvWrNntgg6ppu6kNjMbckB3UkfEFRHRFRFdnZ2de/x6aeJOajOzIWUGxGrg8ML23Hxf2dfutmrqTmozsyFlBsQyYIGk+ZJagLOAJWO89gbgLZKm553Tb8n3laqSj4PwSGozsxIDIiJqwHlkf9gfAK6NiOWSLpF0KoCkV0jqAd4NXC5peX7tOuAzZCGzDLgk31eqdKgG4buYzMyolPniEbEUWDpq38WF58vImo+aXXsVcFWZ5RtteCS1m5jMzA7sTuq9zSOpzcy2cUAUVD1Zn5nZMAdEQZp4JLWZ2RAHRIHnYjIz28YBUTA8ktoBYWbmgCjatmCQm5jMzBwQBZ6sz8xsGwdEgaf7NjPbxgFRUE18m6uZ2RAHREHFndRmZsMcEAXp8G2ubmIyM3NAFHgktZnZNg6IAk/3bWa2jQOioOImJjOzYQ6IgiQRidxJbWYGDojnqKSJFwwyM8MB8RzVRNRdgzAzc0CMVkkT38VkZkbJASFpkaSHJK2UdEGT462Svpcfv13SvHz/PElbJd2TP75WZjmLKoncSW1mRolrUktKgcuAk4AeYJmkJRFxf+G0c4H1EXG0pLOAvwPOzI89HBELyyrf9lRSuZPazIxyaxAnACsj4pGIGACuAU4bdc5pwDfz59cBb5akEsu0U5XETUxmZlBuQMwBVhW2e/J9Tc+JiBqwEZiZH5sv6W5JP5f0+mY/QNJiSd2SutesWbNXCl1J5dlczczYfzupnwCOiIjjgI8C35V0yOiTIuKKiOiKiK7Ozs698oMriZuYzMyg3IBYDRxe2J6b72t6jqQKMBVYGxH9EbEWICLuBB4GXlhiWYdV08Sd1GZmlBsQy4AFkuZLagHOApaMOmcJcE7+/F3AzyIiJHXmndxIegGwAHikxLIOq6TyXExmZpR4F1NE1CSdB9wApMBVEbFc0iVAd0QsAa4EviVpJbCOLEQA3gBcImkQaAAfioh1ZZW1KE0SBh0QZmblBQRARCwFlo7ad3HheR/w7ibXXQ9cX2bZtqeaiJqbmMzM9ttO6nHjcRBmZhkHBECjnj3IOql9m6uZmQMC1j8K/7gQHvg3IFt21APlzMwcEDA1vxO3+0ogG0k96CYmMzMHBEkKXR+A3/0CnllBNXUntZkZOCAyx70fkgp0/zOVNPE4CDMzHBCZyYfCMe+Ae75DOwNeUc7MDAfENl3nQt8GXr75Ft/mamaGA2Kbea+DWS/kNeuX0DdYZ6DmWoSZTWwOiCESdP05R/Qu5/lbV3Dql3/FvT0bx7tUZmbjxgFR9LKzoNLOlQtuo3/zek7/yn/wuX9/kE19g+NdMjOzfa7UuZgOOO3TYeF7eX73ldzCEp6afAS//I95XPqrF9E44jW8/Lgu3nTMYcya3DreJTUzK50iDo4O2a6uruju7t7zF6rX4NFfwOo7oedOao/dQaVvLQBrYir3NI7m8erhDEydT7VzAZNnHMaUqTOZOn0mM6ZNY9aUNqa1V0mScV051cxsTCTdGRFdzY65BjFaWoGj3pQ9gEoErH2Y+P1/UHngFrqe+E+m9P6WyvpBWD/y0v6o8lRM4xFmsCGdwdaWGQy2TifaZ6JJM6l0TKc6eQZth8ykffpspkydxrSOFqZ3VGmvpozzctxmZiM4IHZGgllHo1lHM/34fG2jRh029hBrH2brxjVs3rSOrZvWMfjsM2jzk3T2Ps0R/Y/TMXgfk/ufhU3NX3pTtPNkzOCxmEqv2hhIJ1GvdFBP22lUskdabaWjKtor0FZNiNZDqLfNoNE+k+iYSdo+lWpH9mihRrWxlWp9C0mjBmkrVFpQpZXWtjYmtbfT1tJKkrrrycx2zgGxO5IUph+Jph9JB9Cxo3PrNdi6HnrX0r95Lb2b1rJ14zPUNj5BbHqC9mefYF7fMySDm6nUnqJa76Va66O1r4+Ecpr/tkYLmzSZjUxhiyaRCqqq06IaQcKmZBqb0qlsTqaSJAltSZ2WpEFFQSghSAmJSFuItI2otJImCa300xKDVBt9VLY+Q0vfGtr7nyFtDLAlncrmdCq9lan0th5KX8dsalNmk3bMYFJryqRqQntViAb1eoNo1CFJaWvroKVtEm0dHQjRaDSIqBNKqbR0kLa0k7a0Q62fGNiSPSJotEwmWqcQ1UlUk6BKnWoMUk2FWjqg2gFpNXtDIqBRy54rhaQQoI0GRD07J61mXxjMJggHRNnSCkzuhMmdtB4KrcD0sVwXAbV+qA9AktIg4dm+OgNb1lHf/Az1Z5+m0buO+tZNxNaNRP8mamphMG2nP+mgoRQ1BknqA6g+QL3WT31wgHptAA1sobW2iZbBTRxS20QtEgapsJGUtDHItMZ6juh/lCmNrOpTI2WQlAYiIRBBSoMKg7Qx8g6vvqjSRwtr4xCeTqazKX0BjbSFQxobOaS+idl9Pcx89pe0Mv53htVDCEj03CCukZAQzwnpWiTUlFKjQp2UulLqVKjn+xqq0Jd00F+ZwkBlCo1KO5JIJJIEpCS7dVAJCBr5O1oPQVpFlRZIW1GSgkAAESRRQ43sQf6IRp2IRjZNTFKBtAWSCpJQIoRIBakapAQkFWrVydSrk2lUO0gVVKNGhUEk0ah0EJU2otKGEEPdaEkikkoLJFWSSoXslQNQ9rtVqyRpFaVVEkFCA0UgBSQpSipoKHiVZNcn+XtPkCZCSrIvXsrDeUQQK9/O/6v8vKHzleT7k5HHGvUs3Bt1ILYdU5JtF/tfh18rLbyeYLAPep+BLWuyL3ptU2FSZ/aotOVLBdRoDGzl6cceYO3vl7P1iYeI/s2odTJJ6yQqbZMhbc2+UFVaSAWtja20NPqoNPpBKY2kQj1pQdV2WibPpGXKDNqmzIAkHf4UJmlKW7VKJS38HkPlTqtZ2fayUgNC0iLgH8mWHP1GRFw66ngr8C/A8cBa4MyIeDQ/diFwLlAHPhIRN5RZ1v2OBNW27EF2P/LUFuCQycAR+7QoO7xnKwLqA9RqNWpJC/11qNcbHN5W5ajKdpqyImDLM/SvW0XvpmfoHYzsMVAHpShNSJOUqNfo7+tlsL+Xwb6tQJBkf2VRNKDWB7U+VOujnrTSqLRTr7QjRKXeS7W+hergFuokDFBhIFIajSBt9JHW+0nq/UjQUCX7Qx1Bo1GnUa8TjTpKUtI0JalUsz/UjUFUr0FjIPsjXc/+UKtRI4nskcYg1VovbQMbmNa3mpboy3/n7H+yP6vZH6bsn332zz8L3DotDNKi+nPeskaIQVJqpNRJqZFQJ6FBQkqDljyyKtRQ/jNEUM9jrk5ClRrVJq9tzQ19IRqLBHhe/miE6KWVDvqbfvkow8Mtf8BRf337Xn/d0gJCUgpcBpwE9ADLJC2JiPsLp50LrI+IoyWdBfwdcKakY8nWp34xMBu4WdILI8Kf7v2NBJVWKpVWKkDbWK+Z3Enr5M6x16gOMo1G0Iihb88a3jdQb7BxsE6tNkhksURE9u0xkZCyb/QdaUIlEWkiGgGD9QaD9Qb99aAeQb2RPWr1YLCRHavXG1DrJxncjAY2UyNhoFFhUFVq9TpJrQ/Vt5LWthJkrWsNlNVU6jWiPkA0asNfvkPZMeqD2f5GLWutywMJAhoNFDUU9TwkGygaRARBVvZ6gKKRhVo0IBp5dEb2JT8CaAyHbBINRIMk6tnrROQ1hQZQz18jf/08RBuQ1Wrynz8UoZltP5eo59vZufWkhb6WmQy0zqDWcgittc20D66nY3AtlcYAkVQIVYi0hZZZL2Dmkcdw+NEvZsqkyfQN1Nm0eRO9z24ian00av1Q66fWgIGknT610UcLIqjEIGnUaPRvZmDzOmqb1xNbN6CoI2VfIqJRz/5/rtWo1WrZ+9TIyt067TCOKuFzWmYN4gRgZUQ8AiDpGuA0oBgQpwH/K39+HfBlZf9aTgOuiYh+4HeSVuav95sSy2u2zySJSNBz9rUlKW3VFGgZ82ulgnT4urE4bOwFtd3W3lqhvXUGzJwx3kXZbWXezjIHWFXY7sn3NT0nImrARmDmGK9F0mJJ3ZK616xZsxeLbmZmB/T9jhFxRUR0RURXZ2fneBfHzOygUmZArAYOL2zPzfc1PUdSBZhK1lk9lmvNzKxEZQbEMmCBpPmSWsg6nZeMOmcJkI8+413AzyKb+2MJcJakVknzgQXAHSWW1czMRimtkzoiapLOA24gu831qohYLukSoDsilgBXAt/KO6HXkYUI+XnXknVo14AP+w4mM7N9y5P1mZlNYDuarO+A7qQ2M7PyOCDMzKypg6aJSdIa4Pd78BKzgGf2UnEOJn5fmvP70pzfl+b25/flyIhoOk7goAmIPSWpe3vtcBOZ35fm/L405/eluQP1fXETk5mZNeWAMDOzphwQ21wx3gXYT/l9ac7vS3N+X5o7IN8X90GYmVlTrkGYmVlTDggzM2tqwgeEpEWSHpK0UtIF412e8SLpcEm3SLpf0nJJ5+f7Z0i6SdKK/L8TcQE4JKWS7pb0//Lt+ZJuzz8338snpJxQJE2TdJ2kByU9IOnV/ryApP+R/xu6T9LVktoO1M/LhA6IwrKoJwPHAu/JlzudiGrAxyLiWOBVwIfz9+IC4KcRsQD4ab49EZ0PPFDY/jvgHyLiaGA92fK5E80/Av8eEX8AvIzs/ZnQnxdJc4CPAF0R8RKyiUqHllM+4D4vEzogKCyLGhEDwNCyqBNORDwREXflz58l+8c+h+z9+GZ+2jeB08elgONI0lzgFOAb+baAN5EtkwsT8H2RNBV4A9mMzETEQERswJ8XyGbJbs/XuOkAnuAA/bxM9IAY09KmE42kecBxwO3AYRHxRH7oSSbmgsZfBP4n0Mi3ZwIb8mVyYWJ+buYDa4B/zpveviFpEhP88xIRq4G/Bx4jC4aNwJ0coJ+XiR4QNoqkycD1wF9GxKbisXwxpwl1X7SktwNPR8Sd412W/UwFeDnw1Yg4DtjCqOakCfp5mU5Wi5oPzAYmAYvGtVB7YKIHhJc2LZBUJQuH70TED/LdT0l6fn78+cDT41W+cfJa4FRJj5I1Qb6JrO19Wt6EABPzc9MD9ETE7fn2dWSBMdE/LycCv4uINRExCPyA7DN0QH5eJnpAjGVZ1Akhb1e/EnggIr5QOFRcFvYc4Ef7umzjKSIujIi5ETGP7PPxs4h4H3AL2TK5MDHflyeBVZJelO96M9kKkBP680LWtPQqSR35v6mh9+WA/LxM+JHUkt5G1sY8tCzqZ8e3ROND0uuAXwL3sq2t/a/J+iGuBY4gm079jIhYNy6FHGeS3gj8VUS8XdILyGoUM4C7gbMjon8ci7fPSVpI1nHfAjwC/BnZl84J/XmR9GngTLI7A+8G/htZn8MB93mZ8AFhZmbNTfQmJjMz2w4HhJmZNeWAMDOzphwQZmbWlAPCzMyackCY7QckvXFopliz/YUDwszMmnJAmO0CSWdLukPSPZIuz9eJ2CzpH/I1AH4qqTM/d6Gk2yT9VtIPh9ZGkHS0pJsl/aekuyQdlb/85ML6Ct/JR+KajRsHhNkYSTqGbITsayNiIVAH3kc2IVt3RLwY+DnwqfySfwE+ERF/SDZCfWj/d4DLIuJlwGvIZv2EbAbdvyRbm+QFZHP4mI2bys5PMbPcm4HjgWX5l/t2ssnoGsD38nO+DfwgXy9hWkT8PN//TeD7kqYAcyLihwAR0QeQv94dEdGTb98DzAN+VfpvZbYdDgizsRPwzYi4cMRO6aJR5+3u/DXFuXnq+N+njTM3MZmN3U+Bd0k6FIbX6z6S7N/R0Eyd7wV+FREbgfWSXp/vfz/w83y1vh5Jp+ev0SqpY1/+EmZj5W8oZmMUEfdL+iRwo6QEGAQ+TLZYzgn5safJ+ikgm9b5a3kADM12CllYXC7pkvw13r0Pfw2zMfNsrmZ7SNLmiJg83uUw29vcxGRmZk25BmFmZk25BmFmZk05IMzMrCkHhJmZNeWAMDOzphwQZmbW1P8HLgFPk9JJi5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 6s 118ms/step - loss: 0.5281 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02172, saving model to best_model.h5\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 4s 101ms/step - loss: 0.0190 - val_loss: 0.0159\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02172 to 0.01595, saving model to best_model.h5\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 4s 106ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01595 to 0.01242, saving model to best_model.h5\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 3s 98ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01242 to 0.01120, saving model to best_model.h5\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 3s 100ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01120 to 0.00973, saving model to best_model.h5\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 3s 97ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00973 to 0.00906, saving model to best_model.h5\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 3s 97ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00906 to 0.00856, saving model to best_model.h5\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 3s 96ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00856 to 0.00819, saving model to best_model.h5\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 3s 95ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00819 to 0.00790, saving model to best_model.h5\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 3s 95ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00790\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 3s 97ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00790 to 0.00758, saving model to best_model.h5\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 4s 104ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00758\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 3s 93ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00758 to 0.00752, saving model to best_model.h5\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 3s 98ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00752\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 4s 113ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00752 to 0.00704, saving model to best_model.h5\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 4s 110ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00704\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 3s 96ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00704 to 0.00680, saving model to best_model.h5\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 3s 95ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00680\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 3s 89ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00680 to 0.00673, saving model to best_model.h5\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 3s 95ms/step - loss: 0.0067 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00673\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 3s 88ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00673\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 3s 89ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00673 to 0.00665, saving model to best_model.h5\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 3s 88ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00665 to 0.00629, saving model to best_model.h5\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 3s 87ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00629\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 3s 86ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00629 to 0.00616, saving model to best_model.h5\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 3s 87ms/step - loss: 0.0059 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00616\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 3s 86ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00616\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 3s 85ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00616 to 0.00609, saving model to best_model.h5\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 3s 87ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00609\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 3s 86ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00609 to 0.00595, saving model to best_model.h5\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 3s 90ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00595 to 0.00581, saving model to best_model.h5\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 3s 84ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00581 to 0.00554, saving model to best_model.h5\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 3s 94ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00554\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 3s 83ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00554\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 3s 83ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00554\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 3s 83ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00554 to 0.00549, saving model to best_model.h5\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 3s 83ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00549 to 0.00544, saving model to best_model.h5\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 3s 84ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00544\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 3s 84ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00544\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 3s 89ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00544\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 3s 88ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00544 to 0.00518, saving model to best_model.h5\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 3s 88ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00518 to 0.00478, saving model to best_model.h5\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 3s 88ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00478\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 3s 86ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00478\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 3s 86ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00478 to 0.00467, saving model to best_model.h5\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 3s 86ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00467\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 3s 88ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00467\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 3s 91ms/step - loss: 0.0046 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00467\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 3s 93ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00467\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 3s 92ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00467 to 0.00420, saving model to best_model.h5\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 3s 93ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00420\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 3s 92ms/step - loss: 0.0047 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00420\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 3s 94ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00420\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 3s 95ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00420\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 3s 96ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00420\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 3s 94ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00420\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 3s 96ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00420\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 3s 96ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00420\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 4s 102ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00420\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 3s 99ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00420\n",
      "Epoch 00060: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_subset = df[['seconds_since_last_action', 'label']]\n",
    "inputdf = pd.concat([df[['assignment_log_id', 'student_user_xid']], pd.get_dummies(df['extended_action_name']), data_subset], axis=1)\n",
    "\n",
    "# Call model.fit 10 times and output predictions and actual values (calculate metrics later: auc, kappa, recall)\n",
    "# Call model.predict passing in test\n",
    "X_train_predict, X_test_predict = [], []\n",
    "X_train, Y_train = [None for i in range(10)], [None for i in range(10)]\n",
    "X_test, Y_test = [None for i in range(10)], [None for i in range(10)]\n",
    "\n",
    "# inputs = keras.Input(shape=(None, input_cols), dtype=\"float32\")\n",
    "\n",
    "for i in range(0, 10):\n",
    "    test, train = holdout_split(i, inputdf)\n",
    "    X_train[i], Y_train[i] = create_xy(train)\n",
    "    X_test[i], Y_test[i] = create_xy(test) \n",
    "\n",
    "for i in range(0, 10):\n",
    "    lstm_model = keras.Sequential([\n",
    "        keras.layers.LSTM(n_units, input_shape=(None, input_cols), return_sequences=True), \n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Notes: binary cross entropy loss function, optimization: adam or adagrad\n",
    "    lstm_model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "#         loss='categorical_crossentropy',\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    \n",
    "    # simple early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    \n",
    "    history = lstm_model.fit(\n",
    "        tf.keras.preprocessing.sequence.pad_sequences(X_train[i], padding='post'), # TODO: Does this need to get padded to 249?\n",
    "        tf.keras.preprocessing.sequence.pad_sequences(Y_train[i], padding='post'),\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=val_split,\n",
    "        callbacks=[es, mc]\n",
    "    )\n",
    "\n",
    "    saved_model = load_model('best_model.h5')\n",
    "#     X_train_predict.append(lstm_model.predict(tf.keras.preprocessing.sequence.pad_sequences(X_train)))\n",
    "    X_test_predict.append(saved_model.predict(tf.keras.preprocessing.sequence.pad_sequences(X_test[i])))\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "chinese-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and remove post padding\n",
    "Y_flattened = []\n",
    "for i in range(10):\n",
    "#     print(\"Base length:\", len(Y_test[i]))\n",
    "    Y_test_flat = np.array([])\n",
    "    for seq in Y_test[i]:\n",
    "        Y_test_flat = np.append(Y_test_flat,seq.ravel())\n",
    "#     Y_flattened.append(Y_test_flat.reshape((-1,1)))\n",
    "    Y_flattened.append(Y_test_flat)\n",
    "\n",
    "#     print(\"Flattened length:\", len(Y_test_flat.reshape((-1,1))))\n",
    "#     print(\"First sequence:\", len(Y_test_flat.reshape((-1,1))) / len(Y_test[i]))\n",
    "#     print(\"First length:\", len(Y_test[i][0]))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dense-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "#     print(\"Base length:\", len(X_test_predict[i]))\n",
    "    predict_test_flat = np.array([])\n",
    "    for seq in X_test_predict[i]:\n",
    "        predict_test_flat = np.append(predict_test_flat, seq.ravel())\n",
    "    predict_test_flat.reshape((-1,1))\n",
    "#     print(\"Flattened length:\", len(predict_test_flat.reshape((-1,1))))\n",
    "#     print(\"Per sequence:\", len(predict_test_flat.reshape((-1,1))) / len(X_test_predict[i]))\n",
    "#     print(\"First length:\", len(X_test_predict[i][0]))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fourth-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_unpadded = []\n",
    "for i in range(len(Y_test)):\n",
    "    predict = np.array([])\n",
    "    for j in range(len(Y_test[i])):\n",
    "        unpadded_length = len(Y_test[i][j])\n",
    "        predict = np.append(predict, X_test_predict[i][j][:unpadded_length])\n",
    "    predict_unpadded.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "gorgeous-surface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8547, 8547)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_flattened[0]), len(predict_unpadded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "august-filing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score Fold 0: 0.63 AUC\n",
      "Test Score Fold 1: 0.61 AUC\n",
      "Test Score Fold 2: 0.67 AUC\n",
      "Test Score Fold 3: 0.64 AUC\n",
      "Test Score Fold 4: 0.71 AUC\n",
      "Test Score Fold 5: 0.66 AUC\n",
      "Test Score Fold 6: 0.54 AUC\n",
      "Test Score Fold 7: 0.69 AUC\n",
      "Test Score Fold 8: 0.66 AUC\n",
      "Test Score Fold 9: 0.65 AUC\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_flattened[i], predict_unpadded[i])\n",
    "    print('Test Score Fold %d: %.2f AUC' % (i, metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ignored-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score Fold 0: 0.000000 Kappa\n",
      "Test Score Fold 1: -0.000344 Kappa\n",
      "Test Score Fold 2: 0.000000 Kappa\n",
      "Test Score Fold 3: -0.000175 Kappa\n",
      "Test Score Fold 4: 0.000000 Kappa\n",
      "Test Score Fold 5: -0.000378 Kappa\n",
      "Test Score Fold 6: -0.000460 Kappa\n",
      "Test Score Fold 7: 0.018943 Kappa\n",
      "Test Score Fold 8: -0.000353 Kappa\n",
      "Test Score Fold 9: 0.000000 Kappa\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    kappa = metrics.cohen_kappa_score(Y_flattened[i], np.where(predict_unpadded[i] > 0.5, 1, 0))\n",
    "    print('Test Score Fold %d: %f Kappa' % (i, kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eight-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score Fold 0: 0.148674 RMSE\n",
      "Test Score Fold 1: 0.160985 RMSE\n",
      "Test Score Fold 2: 0.146772 RMSE\n",
      "Test Score Fold 3: 0.141683 RMSE\n",
      "Test Score Fold 4: 0.151697 RMSE\n",
      "Test Score Fold 5: 0.164510 RMSE\n",
      "Test Score Fold 6: 0.146594 RMSE\n",
      "Test Score Fold 7: 0.148104 RMSE\n",
      "Test Score Fold 8: 0.148914 RMSE\n",
      "Test Score Fold 9: 0.154043 RMSE\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    testScore = metrics.mean_squared_error(Y_flattened[i], predict_unpadded[i], squared=False)\n",
    "    print('Test Score Fold %d: %f RMSE' % (i, testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "basic-attendance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, None, 50)          15000     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 1)           51        \n",
      "=================================================================\n",
      "Total params: 15,051\n",
      "Trainable params: 15,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "significant-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'single_behavior_model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-2a53e723db80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'single_behavior_model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'single_behavior_model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Code\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2244\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2245\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2246\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Code\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1494\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[0;32m   1498\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Code\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fp, filename)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'single_behavior_model.png'"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "# import pydot as pyd\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# keras.utils.vis_utils.pydot = pyd\n",
    "\n",
    "plot_model(saved_model, to_file='single_behavior_model.png')\n",
    "data = plt.imread('single_behavior_model.png')\n",
    "plt.imshow(data)\n",
    "plt.show()\n",
    "\n",
    "# def visualize_model(model):\n",
    "#     return SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "# visualize_model(saved_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Code)",
   "language": "python",
   "name": "pycharm-54f6765a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
